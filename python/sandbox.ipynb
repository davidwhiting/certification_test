{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Quick and dirty functions to create unique randomized tests. These can be improved, right now they are just scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_choice(question, choices, which=1, randomize=True, aota=False, \n",
    "    nota=False, none_prob=0.2, number=None):\n",
    "    \"\"\"\n",
    "    Create a multiple choice question randomizing order\n",
    "        number : question number on test (for formatting)\n",
    "        question : string\n",
    "        choices : list of string \n",
    "        which : which choice is correct (defaults to first in list)\n",
    "            if -1 then \"None of the above\" is correct and a correct answer \n",
    "                wasn't provided\n",
    "            if 0 then \"All of the above\" is correct \n",
    "        randomize : randomize order of options, making questions unique\n",
    "        aota : include \"All of the above\" as an option\n",
    "        nota : include \"None of the above\" as an option \n",
    "        none_prob : probability that \"None of the above\" is right (If a correct \n",
    "            answer is supplied, it will be removed with this probability.) \n",
    "\n",
    "\n",
    "    Note: \n",
    "       - \"All of the above\" always appears before \"None of the above\" in \n",
    "         options and after random shuffle\n",
    "       - If a correct answer is removed and the answer made \"None of the above\",\n",
    "         and there are only 3 remaining options, then \"All of the above\" will \n",
    "         also be added \n",
    "    \n",
    "    \"\"\"\n",
    "    import random\n",
    "    import string\n",
    "\n",
    "    AOTA = \"All of the above\"\n",
    "    NOTA = \"None of the above\"\n",
    "    \n",
    "    # Select right answer if given\n",
    "    if which > 0:\n",
    "        correct = choices[which-1]\n",
    "    elif which == 0:\n",
    "        correct = AOTA\n",
    "    else: # which == -1:\n",
    "        correct = NOTA\n",
    "        \n",
    "    # Randomize order of options before appending 'All ...' or 'None ...'\n",
    "    if randomize:\n",
    "        random.shuffle(choices)\n",
    "\n",
    "    # Append 'All of the above'\n",
    "    if aota or which == 0 :\n",
    "        choices.append(AOTA)\n",
    "\n",
    "    # Append 'None of the above'\n",
    "    if nota or which == -1:\n",
    "        choices.append(NOTA)\n",
    "\n",
    "    # Remove the correct answer with probability none_prob\n",
    "    if which > 0 and nota and none_prob > 0:\n",
    "        if random.random() <= none_prob:\n",
    "            choices.remove(correct)\n",
    "            correct = NOTA\n",
    "            # if not enough options after removing the correct answer, add ALL\n",
    "            if (not aota) and len(choices) <= 4:\n",
    "                choices.insert(len(choices)-1, AOTA)\n",
    "    \n",
    "    # get correct answer\n",
    "    answer = string.ascii_lowercase[choices.index(correct)]\n",
    "\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "\n",
    "    # Format the question with options                \n",
    "    for i, choice in enumerate(choices):\n",
    "        question += blank + string.ascii_lowercase[i] + \") \" + choice\n",
    "\n",
    "    return question, answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_true_false(question, answer, number=None):\n",
    "    \"\"\"\n",
    "    Format a True/False question\n",
    "    \"\"\"\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "        \n",
    "    question += blank + \"a) True\"\n",
    "    question += blank + \"b) False\"\n",
    "\n",
    "    if answer.lower() in ['t', 'true']:\n",
    "        answer = \"a\"\n",
    "    else:\n",
    "        answer = \"b\"\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_question_templates(raw):\n",
    "    \"\"\"\n",
    "    Helper code to save questions imported from the xlsx file into the question_templates table of the database\n",
    "    \n",
    "    This basically has no error checking, and assumes that the line\n",
    "        templates = metadata.tables['question_templates']  \n",
    "    has been run beforehand\n",
    "    \n",
    "    \"\"\"\n",
    "    # If empty, set to database default\n",
    "    if raw[2] == '':   \n",
    "        correct = 1\n",
    "    else:\n",
    "        correct = raw[2]\n",
    "\n",
    "    if raw[3] == '':\n",
    "        randomize = 1\n",
    "    else:\n",
    "        randomize = raw[3]\n",
    "\n",
    "    ins = templates.insert().values(\n",
    "        question = raw[0],\n",
    "        answer = raw[1], \n",
    "        correct = correct, \n",
    "        randomize = randomize, \n",
    "        type = raw[4],\n",
    "        comments = 'labels: ' + raw[5] + '; author: ' + raw[7] \n",
    "    )\n",
    "\n",
    "    conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_list(query, n=None, randomize=True, as_text=False):\n",
    "    \"\"\"\n",
    "    Retrieves a list of id's from the question template table\n",
    "    Alternatively randomize them\n",
    "    \"\"\"\n",
    "    result = conn.execute(query).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "    id = df['id'].to_list()\n",
    "    \n",
    "    if (n is None) or (n == 0):\n",
    "        n = len(id)\n",
    "    # if randomizing order of questions\n",
    "    if randomize:\n",
    "        id = random.sample(id, n)\n",
    "    else:\n",
    "        id = id[0:n]\n",
    "        \n",
    "    # return as a text object to store in database\n",
    "    if as_text:\n",
    "        id = \"(\" + ', '.join(map(str, id)) + \")\"\n",
    "\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_by_name(name):\n",
    "    \"\"\"\n",
    "    Select queries from a test and execute them\n",
    "    \n",
    "    Need to add error checking, etc. into this to make it work.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## using the text() object to execute across multiple tables\n",
    "    sql = \"\"\"\n",
    "    SELECT b.id, a.section, CONCAT(a.prefix, a.definition) AS query, a.randomize, a.n \n",
    "    FROM test_subqueries a, test_definitions b \n",
    "    WHERE a.definition_id=b.id AND b.name= :name\n",
    "    \"\"\"\n",
    "\n",
    "    result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "    \n",
    "    result = []\n",
    "    for i, query in enumerate(df['query']):\n",
    "        tmp = get_id_list( df['query'][i], n=df['n'][i], randomize=df['randomize'][i] )\n",
    "        result = result + tmp # concatenate lists\n",
    "    \n",
    "    result = \"(\" + ', '.join(map(str, result)) + \")\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MySQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "\n",
    "engine = db.create_engine('mysql://root:root@127.0.0.1:8306/certification')\n",
    "#engine = db.create_engine('mysql://root:root@127.0.0.1:8889/certification')\n",
    "conn = engine.connect()\n",
    "\n",
    "# Create a MetaData instance\n",
    "metadata = db.MetaData()\n",
    "\n",
    "# reflect db schma to MetaData\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from question_templates\"\n",
    "#query = \"select * from question_templates where id in (1,3)\"\n",
    "#query = \"select * from question_templates where type = 'Multiple Choice'\"\n",
    "\n",
    "result = conn.execute(query).fetchall()\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Correlation scatterplots are included for any ...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Kiri Nichol</td>\n",
       "      <td>Is the final scoring pipeline always an ensamb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>Can I do multi-label classification in Driverl...</td>\n",
       "      <td>Is multi-class classification supported?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: How do I reduce the size of the MOJO?;...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show your variables which cou...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  Correlation scatterplots are included for any ...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106                                        Kiri Nichol   \n",
       "106  107  How are the final scoring pipelines ensembles ...   \n",
       "107  108  [\"stacked ensemble\", \"mean of the individual m...   \n",
       "108  109  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "109  110  Can I do multi-label classification in Driverl...   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"        1          1   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...        1          1   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...        1          1   \n",
       "3                  [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"        1          0   \n",
       "4                                               \"True\"        1          1   \n",
       "..                                                 ...      ...        ...   \n",
       "105  Is the final scoring pipeline always an ensamb...        1          1   \n",
       "106                                             \"True\"        1          1   \n",
       "107                                            \"False\"        1          1   \n",
       "108                                             \"True\"        1          1   \n",
       "109           Is multi-class classification supported?        0          1   \n",
       "\n",
       "                type  aota  nota  epsilon  enabled  \\\n",
       "0         True/False     0     0   0.0001        0   \n",
       "1    Multiple Choice     0     0   0.0001        0   \n",
       "2    Multiple Choice     0     0   0.0001        0   \n",
       "3    Multiple Choice     0     0   0.0001        0   \n",
       "4         True/False     0     0   0.0001        0   \n",
       "..               ...   ...   ...      ...      ...   \n",
       "105  Multiple Choice     0     0   0.0001        0   \n",
       "106       True/False     0     0   0.0001        0   \n",
       "107       True/False     0     0   0.0001        0   \n",
       "108       True/False     0     0   0.0001        0   \n",
       "109  Multiple Choice     0     0   0.0001        0   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "109  labels: How do I reduce the size of the MOJO?;... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-06 13:41:05  \n",
       "1   2020-05-06 13:41:05  \n",
       "2   2020-05-06 13:41:05  \n",
       "3   2020-05-06 13:41:05  \n",
       "4   2020-05-06 13:41:05  \n",
       "..                  ...  \n",
       "105 2020-05-06 13:41:05  \n",
       "106 2020-05-06 13:41:05  \n",
       "107 2020-05-06 13:41:05  \n",
       "108 2020-05-06 13:41:05  \n",
       "109 2020-05-06 13:41:05  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Questions from Excel\n",
    "Only need to do this once. Have changed from `db=` to `xlsx=` to avoid name collisions with above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheet1', 'Sheet2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pylightxl\n",
    "xl = pylightxl.readxl('Questions.xlsx')\n",
    "xl.ws_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1036, 8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xl = xl.ws('Sheet1')\n",
    "xl.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question Text',\n",
       " 'Answers set (multiple choice / checkbox / matching / true-false)',\n",
       " 'Correct',\n",
       " 'Randomize',\n",
       " 'Type',\n",
       " 'Tags',\n",
       " 'Difficulty (optional)',\n",
       " 'Contributor']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Examples of how to use this:\n",
    "## Get content by cell address\n",
    "#xl.address('A3')\n",
    "\n",
    "headers = xl.row(2)\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_templates',\n",
       " 'questions',\n",
       " 'test_definitions',\n",
       " 'test_subqueries',\n",
       " 'tests']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MySQL Tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'question', 'answer', 'correct', 'randomize', 'type', 'aota', 'nota', 'epsilon', 'enabled', 'comments', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "# Template fields\n",
    "templates = metadata.tables['question_templates']\n",
    "print(templates.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only need to do once\n",
    "#for r in range(3, 113):\n",
    "#    raw = db.row(r)\n",
    "#    update_question_templates(raw)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'description', 'dai_version', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "testdef = metadata.tables['test_definitions']\n",
    "print(testdef.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'definition_id', 'section', 'prefix', 'definition', 'n', 'randomize', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "subquery = metadata.tables['test_subqueries']\n",
    "print(subquery.columns.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below: Insert some test definitions manually (this only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add an example test definition to the database\n",
    "\n",
    "ins = testdef.insert().values(\n",
    "    name = 'All',\n",
    "    description = \"All questions in database\", \n",
    "    )\n",
    "## Only needs to be done once\n",
    "#conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This query should always return only 1 result, \n",
    "## the id which we will pass to the subquery table for tests with multiple sections\n",
    "## (multiple sql queries to select test questions)\n",
    "\n",
    "query = \"select id from test_definitions where name='All'\"\n",
    "result = conn.execute(query).fetchall()\n",
    "id = result[0]['id']\n",
    "\n",
    "ins = subquery.insert().values(\n",
    "    definition_id = id,\n",
    "    randomize = False\n",
    "    )\n",
    "#conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"TF then MC\"\n",
    "ins = testdef.insert().values(\n",
    "    name = name,\n",
    "    description = \"First TF then MC\", \n",
    "    )\n",
    "conn.execute(ins)\n",
    "\n",
    "## This query should always return only 1 result\n",
    "query = \"select id from test_definitions where name='\" + name + \"'\"\n",
    "result = conn.execute(query).fetchall()\n",
    "id = result[0]['id']\n",
    "\n",
    "statements = [\"where type='True/False'\", \"where type='Multiple Choice'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, query in enumerate(statements):\n",
    "    ins = subquery.insert().values(\n",
    "        definition_id = id,\n",
    "        section = i+1, \n",
    "        definition = query,\n",
    "        randomize = False\n",
    "    )\n",
    "    conn.execute(ins)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to automate the above with some code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test from test definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import text\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>query</th>\n",
       "      <th>randomize</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SELECT id FROM question_templates where type='...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SELECT id FROM question_templates where type='...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   section                                              query  randomize  n\n",
       "0        1  SELECT id FROM question_templates where type='...          0  0\n",
       "1        2  SELECT id FROM question_templates where type='...          0  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"TF then MC\"\n",
    "\n",
    "## using the text() object to execute across multiple tables\n",
    "sql = \"\"\"\n",
    "   SELECT b.id, a.section, CONCAT(a.prefix, a.definition) AS query, a.randomize, a.n \n",
    "   FROM test_subqueries a, test_definitions b \n",
    "   WHERE a.definition_id=b.id AND b.name= :name\n",
    "   \"\"\"\n",
    "result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_queries_by_name(\"TF then MC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1, 5, 8, 9, 11, 14, 17, 18, 20, 21, 23, 29, 30, 31, 32, 33, 34, 41, 42, 48, 49, 51, 61, 62, 64, 65, 66, 68, 69, 76, 77, 78, 84, 85, 87, 88, 89, 91, 93, 94, 96, 97, 98, 101, 103, 104, 105, 107, 108, 109, 2, 3, 4, 6, 7, 10, 12, 13, 15, 16, 19, 22, 24, 25, 26, 27, 28, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 67, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 83, 86, 90, 92, 95, 99, 100, 102, 106, 110)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the result to the tests table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'definition_id', 'seed', 'question_list', 'experiments', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "tests = metadata.tables['tests']\n",
    "print(tests.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed was: 1778253695752227620\n"
     ]
    }
   ],
   "source": [
    "# generate random seed\n",
    "seed = random.randrange(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x11b21f588>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to get the definition id programatically\n",
    "ins = tests.insert().values(\n",
    "    definition_id = 2,\n",
    "    seed = seed,\n",
    "    question_list = result\n",
    "    )\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new test from the tests table\n",
    "\n",
    "### Populates the Questions table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to iterate over the `questions` and\n",
    "1. pull a template from the `question_template` table,\n",
    "2. create the question text and the answer, and\n",
    "3. save the information back to the `questions` table.\n",
    "\n",
    "The multiple communication cycles between MySQL and Python are slightly inefficient, but very straightforward. The inefficiency here is irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 1\n",
    "\n",
    "query = \"select id, seed, question_list, experiments, none_prob from tests where id=:id\"\n",
    "result = conn.execute(text(query), id=test_id).fetchall()\n",
    "\n",
    "# Retrieve experiment information\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "\n",
    "seed = df['seed'][0]\n",
    "question_list = df['question_list'][0]\n",
    "experiments = df['experiments'][0]\n",
    "none_prob = df['none_prob'][0]\n",
    "\n",
    "# create list from database question_list string\n",
    "ql = question_list[1:-1].split(\",\")\n",
    "question_list = [int(i) for i in ql]\n",
    "\n",
    "# question table where questions and answers will be entered\n",
    "questions = metadata.tables['questions']\n",
    "\n",
    "# general query for retrieving question templates from db\n",
    "query = \"select * from question_templates where id=:id\"\n",
    "sql = text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert or Update on Duplicate statement\n",
    "insert_stmt = \"\"\"\n",
    "        insert into questions (question, answer, number, test_id, template_id) \n",
    "        values (:question, :answer, :number, :test_id, :template_id) \n",
    "        on duplicate key update\n",
    "          question = :question,\n",
    "          answer = :answer,\n",
    "          number = :number,\n",
    "          test_id = :test_id,\n",
    "          template_id = :template_id\n",
    "        \"\"\"\n",
    "\n",
    "insert_sql = text(insert_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Easy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-538b4abac7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_true_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Multiple Choice'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             q, a = make_multiple_choice(df['question'][0], eval(df['answer'][0]), \n\u001b[0m\u001b[1;32m     20\u001b[0m                                     \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'randomize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                     aota=df['aota'][0], nota=df['nota'][0], none_prob=none_prob)\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Easy' is not defined"
     ]
    }
   ],
   "source": [
    "# Set random seed from database\n",
    "random.seed(seed)\n",
    "\n",
    "update_database = False\n",
    "Results = \"\"\n",
    "\n",
    "# loop over all questions to create test\n",
    "for i, id in enumerate(question_list):\n",
    "\n",
    "    result = conn.execute(sql, id=id).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "\n",
    "    if df['enabled'][0]:\n",
    "        \n",
    "        if df['type'][0] == 'True/False':\n",
    "            q, a = make_true_false(df['question'][0], df['answer'][0])\n",
    "        elif df['type'][0] == 'Multiple Choice':\n",
    "            q, a = make_multiple_choice(df['question'][0], eval(df['answer'][0]), \n",
    "                                    which=df['correct'][0], randomize=df['randomize'][0],\n",
    "                                    aota=df['aota'][0], nota=df['nota'][0], none_prob=none_prob)\n",
    "        else:\n",
    "            # Gently exit... replace below with better code\n",
    "            q = \"\"\n",
    "            a = \"\"\n",
    "            \n",
    "        if update_database:\n",
    "            conn.execute(insert_sql,\n",
    "                question = q,\n",
    "                answer = a, \n",
    "                number = i + 1,\n",
    "                test_id = test_id,\n",
    "                template_id = id\n",
    "                )\n",
    "        else:\n",
    "            Results += \"\\n\\n\" + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The graphs shown on the AutoVisualization page are the same for all datasets.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "Which graph will show your variables that could be good candidates for transformation before being used in modeling?\n",
      "a) Outliers\n",
      "b) Correlation Graph\n",
      "c) Skewed Histograms\n",
      "d) Spikey Histograms\n",
      "e) None of the above\n",
      "\n",
      "The ______ plot will indicate variables with anomalous values or points that may lie in an empty region.\n",
      "a) Biplot\n",
      "b) Recommendations\n",
      "c) Outlier\n",
      "d) Data Heatmap\n",
      "e) None of the above\n",
      "\n",
      "Correlation scatterplots are included for any variable pairs that have a correlation higher than what value?\n",
      "a) 0.95\n",
      "b) 0.90\n",
      "c) 0.85\n",
      "d) 0.80\n",
      "e) 0.75\n",
      "\n",
      "Skewed histograms are presented in descending order of skewness.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "In a Biplot, lines represent ________ .\n",
      "a) Missing values\n",
      "b) Dataset rows\n",
      "c) Principal Components\n",
      "d) Dataset columns\n",
      "e) Correlations\n",
      "\n",
      "In a Biplot, points represent ________ .\n",
      "a) Principal Components\n",
      "b) Correlations\n",
      "c) Dataset rows\n",
      "d) Dataset columns\n",
      "e) Missing values\n",
      "\n",
      "The Correlation Graph shows pairwise correlations for numerical variables only.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "In a Parallel Coordinates Plot, each color represents a separate cluster of rows.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "The Radar Plot is the polar version of the ________ . \n",
      "a) Parallel Coordinates Plot\n",
      "b) Data Heatmap\n",
      "c) Biplot\n",
      "d) Correlation Graph\n",
      "\n",
      "You cannot delete a dataset that was used in an active experiment.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "If a column’s data type or distribution does not match the manner in which you want the column to be handled during an experiment, which would you change to make the column fit bettter?\n",
      "a) Storage Type\n",
      "b) Logical Type\n",
      "c) Name\n",
      "d) Format\n",
      "\n",
      "Which of the following will allow you to see the distribution of features in a given dataset?\n",
      "a) Dataset -&gt; Details\n",
      "b) Dataset -&gt;Split\n",
      "c) Dataset -&gt; Download\n",
      "d) Dataset-&gt; Predict\n",
      "\n",
      "Data imputation for ingested data is enabled by default.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "For numeric values, which of the following is the default imputation method?\n",
      "a) Max\n",
      "b) Mean\n",
      "c) Median\n",
      "d) Mode\n",
      "e) Min\n",
      "\n",
      "The ______ dataset is only used for tuning the modeling pipeline\n",
      "a) Original\n",
      "b) Validation\n",
      "c) Train\n",
      "d) Test\n",
      "\n",
      "Driverless AI will automatically drop ID columns\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "Driverless AI will not drop columns that have a large number of unique values in experiements\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "If you do not include a validation dataset for an experiement that is not time series, which type of validation technique will Driverless AI use?\n",
      "a) Nested Cross-Validation\n",
      "b) Leave-one-group-out Cross-Validation\n",
      "c) Leave-one-out Cross-Validation\n",
      "d) k-fold Cross-Validation\n",
      "\n",
      "A validation dataset can be used for time series experiments\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "The validation dataset must have the same number of columns as the training dataset.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "The _______ setting will allow you to set the number of unique values that will be used to determine if a column will be treated as an ID column and dropped.\n",
      "a) Max allowed fraction of uniques for integer and categorical cols\n",
      "b) Max number of original features used\n",
      "c) Max number of original features used for FS individual\n",
      "d) Max number of unique values for int/float to be categoricals\n",
      "\n",
      "The weight column is used when computing the test score.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "For regression problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "a) Cluster\n",
      "b) Random\n",
      "c) Stratified\n",
      "d) Systematic\n",
      "\n",
      "For classification problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "a) Cluster\n",
      "b) Stratified\n",
      "c) Random\n",
      "d) Systematic\n",
      "\n",
      "Driverless AI uses what measure to determine whether a binary problem is considered imbalanced by default?\n",
      "a) Minority class is 10 times more common than majority class\n",
      "b) Minority class is 5 times more common than majority class\n",
      "c) Majority class is 10 times more common than minority class\n",
      "d) Majority class is 5 times more common than minority class\n",
      "\n",
      "Which method does Driverless AI use to create validation datasets based on the target variable for classification experiments?\n",
      "a) Clusters\n",
      "b) Stratification\n",
      "c) Oversamples\n",
      "d) Randomly selects\n",
      "\n",
      "Which method does Driverless AI use to create validation datasets based on the target variable for regression experiments?\n",
      "a) Oversamples\n",
      "b) Clusters\n",
      "c) Randomly selects\n",
      "d) Stratification\n",
      "\n",
      "Using a fold column can prevent data leakage and improve generalization\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "Selectivng \"Reproducible\" when setting up an experiment will ensure that repeated runs of the same experiment on the same data will achieve approximately the same results.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "The meaning of \"Reproducible\" can vary depending on Expert Settings.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "In Expert Settings, if the value under \"Max. runtime in minutes before triggering the 'Finish' button\" is reached, the experiment will be automatically aborted. \n",
      "a) True\n",
      "b) False\n",
      "\n",
      "In Expert Settings, if \"Compliant\" is set to \"ON\", Interpretability will automatically be set to ______ .\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "You can use a Time Column if you specify a Fold Column.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "At a low accuracy setting, Driverless AI does which of the following for features and models?\n",
      "a) Both model and feature tracking is performed and an ensemble of all variations occurs\n",
      "b) Each independent main model will evolve independently and be part of an ensemble\n",
      "c) Will evolve and ensemble features on and off that evolve independently\n",
      "d) Varies features and models, but they compete evenly against each other\n",
      "\n",
      "Data shift detection between the train and test dataset occurs at what point?\n",
      "a) Accuracy is &gt;= 5\n",
      "b) Time is &gt; 5\n",
      "c) Interpretability is &gt;= 7\n",
      "d) Accuracy is &lt; 5\n",
      "\n",
      "Monotonicity constraints are used in which models?\n",
      "a) Decision Trees, XGBoost GBM, Light GBM, Light GBM Random Forest, XGBoost Dart, Tensorflow\n",
      "b) Decision Trees, XGBoost GBM, Light GBM, Light GBM Random Forest, XGBoost Dart\n",
      "c) Decision Trees, XGBoost GBM, Light GBM, Light GBM Random Forest, XGBoost Dart, RuleFit\n",
      "d) Decision Trees, XGBoost GBM, Light GBM, Light GBM Random Forest, FTRL\n",
      "\n",
      "Which of the following is true about the weight column?\n",
      "a) It is a required column\n",
      "b) It is not used to compute the test score\n",
      "c) It has no effect on model training\n",
      "d) It is not used when making test set predictions\n",
      "\n",
      "If you do not identify a weight column, all rows will have an observarion weight of what?\n",
      "a) 9999\n",
      "b) 1\n",
      "c) 0\n",
      "d) A random number\n",
      "\n",
      "The experiment preview will not automatically update if you only adjust either the Accuracy, Interpretability, or Time knobs.\n",
      "a) True\n",
      "b) False\n",
      "\n",
      "If you do not select a custom algorithm in the \n",
      "a) True\n",
      "b) False\n",
      "\n",
      "How does Driverless AI determine whether to include models or recipes adjusted by Expert Settings.\n",
      "a) In the order the setting was enabled\n",
      "b) Random Selection\n",
      "c) Always uses all models and recipes\n",
      "d) By hierarchy\n",
      "\n",
      "What setting(s) affects the number of ensemble models under consideration for an experiment?\n",
      "a) Accuracy\n",
      "b) Time\n",
      "c) Interpretability\n",
      "\n",
      "Which of the following is NOT a factor in determining whether Driverless AI employs a validation data set instead of cross-validation?\n",
      "a) True\n",
      "b) False\n"
     ]
    }
   ],
   "source": [
    "print(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ins = questions.insert().values(\n",
    "#            question = q,\n",
    "#            answer = a, \n",
    "#            number = i + 1,\n",
    "#            test_id = test_id,\n",
    "#            template_id = id) \n",
    "\n",
    "#conn.execute(text(stmt), question=\"YES!\", answer=\"\", number=51, test_id=1, template_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(MySQLdb._exceptions.IntegrityError) (1062, \"Duplicate entry '1-1' for key 'test-number'\")\n[SQL: INSERT INTO questions (question, answer, number, test_id, template_id) VALUES (%s, %s, %s, %s, %s)]\n[parameters: ('The graphs shown on the AutoVisualization page are the same for all datasets.\\na) True\\nb) False', 'b', 1, 1, 1)]\n(Background on this error at: http://sqlalche.me/e/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1247\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1248\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m                     )\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0m_mysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry '1-1' for key 'test-number'\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-5388762c7a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m    982\u001b[0m             )\n\u001b[1;32m    983\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m_execute_on_connection\u001b[0;34m(self, connection, multiparams, params)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_execution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_clauseelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectNotExecutableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_clauseelement\u001b[0;34m(self, elem, multiparams, params)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mcompiled_sql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m             \u001b[0mdistilled_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1288\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1480\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                 util.raise_(\n\u001b[0;32m-> 1482\u001b[0;31m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m                 )\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1248\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m                     )\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, query, args)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/cursors.py\u001b[0m in \u001b[0;36m_query\u001b[0;34m(self, q)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/dai-1.8.5.1/lib/python3.6/site-packages/MySQLdb/connections.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0m_mysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bytes_literal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (MySQLdb._exceptions.IntegrityError) (1062, \"Duplicate entry '1-1' for key 'test-number'\")\n[SQL: INSERT INTO questions (question, answer, number, test_id, template_id) VALUES (%s, %s, %s, %s, %s)]\n[parameters: ('The graphs shown on the AutoVisualization page are the same for all datasets.\\na) True\\nb) False', 'b', 1, 1, 1)]\n(Background on this error at: http://sqlalche.me/e/gkpj)"
     ]
    }
   ],
   "source": [
    "# Set random seed from database\n",
    "random.seed(seed)\n",
    "\n",
    "# loop over all questions to create test\n",
    "for i, id in enumerate(question_list):\n",
    "\n",
    "    result = conn.execute(sql, id=id).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "\n",
    "    if df['enabled'][0]:\n",
    "        \n",
    "        if df['type'][0] == 'True/False':\n",
    "            q, a = make_true_false(df['question'][0], df['answer'][0])\n",
    "        elif df['type'][0] == 'Multiple Choice':\n",
    "            q, a = make_multiple_choice(df['question'][0], eval(df['answer'][0]), \n",
    "                                    which=df['correct'][0], randomize=df['randomize'][0],\n",
    "                                    aota=df['aota'][0], nota=df['nota'][0], none_prob=none_prob)\n",
    "        else:\n",
    "            # Gently exit... replace below with better code\n",
    "            q = \"\"\n",
    "            a = \"\"\n",
    "\n",
    "        \n",
    "        ins = questions.insert().values(\n",
    "            question = q,\n",
    "            answer = a, \n",
    "            number = i + 1,\n",
    "            test_id = test_id,\n",
    "            template_id = id\n",
    "            )\n",
    "    \n",
    "        conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"select * from question_templates where id=:id\"\n",
    "#sql = text(query)\n",
    "\n",
    "#result = conn.execute(text(query), id=1).fetchall()\n",
    "\n",
    "#query = \"select question, answer, correct, randomize, type, aota, nota, epsilon, enabled from question_templates where id in \" + question_list\n",
    "\n",
    "#result = conn.execute(query).fetchall()\n",
    "#df = pd.DataFrame(result)\n",
    "#df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Correlation scatterplots are included for any ...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Kiri Nichol</td>\n",
       "      <td>Is the final scoring pipeline always an ensamb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>Can I do multi-label classification in Driverl...</td>\n",
       "      <td>Is multi-class classification supported?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: How do I reduce the size of the MOJO?;...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show your variables which cou...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  Correlation scatterplots are included for any ...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106                                        Kiri Nichol   \n",
       "106  107  How are the final scoring pipelines ensembles ...   \n",
       "107  108  [\"stacked ensemble\", \"mean of the individual m...   \n",
       "108  109  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "109  110  Can I do multi-label classification in Driverl...   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"        1          1   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...        1          1   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...        1          1   \n",
       "3                  [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"        1          0   \n",
       "4                                               \"True\"        1          1   \n",
       "..                                                 ...      ...        ...   \n",
       "105  Is the final scoring pipeline always an ensamb...        1          1   \n",
       "106                                             \"True\"        1          1   \n",
       "107                                            \"False\"        1          1   \n",
       "108                                             \"True\"        1          1   \n",
       "109           Is multi-class classification supported?        0          1   \n",
       "\n",
       "                type  aota  nota  epsilon  enabled  \\\n",
       "0         True/False     0     0   0.0001        0   \n",
       "1    Multiple Choice     0     0   0.0001        0   \n",
       "2    Multiple Choice     0     0   0.0001        0   \n",
       "3    Multiple Choice     0     0   0.0001        0   \n",
       "4         True/False     0     0   0.0001        0   \n",
       "..               ...   ...   ...      ...      ...   \n",
       "105  Multiple Choice     0     0   0.0001        0   \n",
       "106       True/False     0     0   0.0001        0   \n",
       "107       True/False     0     0   0.0001        0   \n",
       "108       True/False     0     0   0.0001        0   \n",
       "109  Multiple Choice     0     0   0.0001        0   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "109  labels: How do I reduce the size of the MOJO?;... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-06 13:41:05  \n",
       "1   2020-05-06 13:41:05  \n",
       "2   2020-05-06 13:41:05  \n",
       "3   2020-05-06 13:41:05  \n",
       "4   2020-05-06 13:41:05  \n",
       "..                  ...  \n",
       "105 2020-05-06 13:41:05  \n",
       "106 2020-05-06 13:41:05  \n",
       "107 2020-05-06 13:41:05  \n",
       "108 2020-05-06 13:41:05  \n",
       "109 2020-05-06 13:41:05  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which graph will show your variables that could be good candidates for transformation before being used in modeling?\n",
      "a) Spikey Histograms\n",
      "b) Skewed Histograms\n",
      "c) Outliers\n",
      "d) Correlation Graph\n",
      "e) None of the above\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778253695752227620"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:50:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Correlation scatterplots are included for any ...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Kiri Nichol</td>\n",
       "      <td>Is the final scoring pipeline always an ensamb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>Can I do multi-label classification in Driverl...</td>\n",
       "      <td>Is multi-class classification supported?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: How do I reduce the size of the MOJO?;...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show your variables which cou...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  Correlation scatterplots are included for any ...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106                                        Kiri Nichol   \n",
       "106  107  How are the final scoring pipelines ensembles ...   \n",
       "107  108  [\"stacked ensemble\", \"mean of the individual m...   \n",
       "108  109  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "109  110  Can I do multi-label classification in Driverl...   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"      NaN        NaN   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...      1.0        1.0   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...      1.0        1.0   \n",
       "3                  [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"      1.0        0.0   \n",
       "4                                               \"True\"      NaN        NaN   \n",
       "..                                                 ...      ...        ...   \n",
       "105  Is the final scoring pipeline always an ensamb...      1.0        1.0   \n",
       "106                                             \"True\"      NaN        NaN   \n",
       "107                                            \"False\"      NaN        NaN   \n",
       "108                                             \"True\"      NaN        NaN   \n",
       "109           Is multi-class classification supported?      0.0        1.0   \n",
       "\n",
       "                type  aota  nota  epsilon  enabled  \\\n",
       "0         True/False   NaN   NaN      NaN        1   \n",
       "1    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "2    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "3    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "4         True/False   NaN   NaN      NaN        0   \n",
       "..               ...   ...   ...      ...      ...   \n",
       "105  Multiple Choice   0.0   0.0   0.0001        0   \n",
       "106       True/False   NaN   NaN      NaN        0   \n",
       "107       True/False   NaN   NaN      NaN        0   \n",
       "108       True/False   NaN   NaN      NaN        0   \n",
       "109  Multiple Choice   0.0   0.0   0.0001        0   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "109  labels: How do I reduce the size of the MOJO?;... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-11 14:50:06  \n",
       "1   2020-05-06 13:41:05  \n",
       "2   2020-05-06 13:41:05  \n",
       "3   2020-05-06 13:41:05  \n",
       "4   2020-05-11 14:49:14  \n",
       "..                  ...  \n",
       "105 2020-05-06 13:41:05  \n",
       "106 2020-05-11 14:49:14  \n",
       "107 2020-05-11 14:49:14  \n",
       "108 2020-05-11 14:49:14  \n",
       "109 2020-05-06 13:41:05  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 41,\n",
       " 42,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 61,\n",
       " 62,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 68,\n",
       " 69,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 84,\n",
       " 85,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 101,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 63,\n",
       " 67,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 86,\n",
       " 90,\n",
       " 92,\n",
       " 95,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 106,\n",
       " 110]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over questions to create a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['type'][i] == 'True/False':\n",
    "    q, a = make_true_false(df['question'][i], df['answer'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graphs shown on the AutoVisualization page are the same for all datasets.\n",
      "a) True\n",
      "b) False\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  50,  51,  52,   1,  53,  54,   2,   3,  55,   4,  56,  57,\n",
       "         5,  58,  59,   6,   7,  60,   8,   9,  61,  10,  62,  63,  64,\n",
       "        65,  66,  11,  12,  13,  14,  15,  16,  67,  68,  69,  70,  71,\n",
       "        72,  17,  18,  73,  74,  75,  76,  77,  19,  20,  78,  21,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  22,  23,  88,  24,  25,\n",
       "        26,  89,  27,  28,  90,  91,  92,  93,  94,  95,  29,  30,  31,\n",
       "        96,  97,  98,  99, 100,  32,  33, 101,  34,  35,  36, 102,  37,\n",
       "       103,  38,  39, 104,  40,  41,  42, 105, 106,  43, 107,  44,  45,\n",
       "        46, 108,  47,  48,  49, 109])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argsort(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['randomize'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "shuffle(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "\n",
    "mystring = \"(\" + df['id'].to_csv(header=False, index=False, line_terminator=\", \")[:-2] + \")\"\n",
    "mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.execute(query).fetchall()\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testquery.insert().values(\n",
    "    name = \"All Enabled\",\n",
    "    definition = \"where enabled=1\",\n",
    "    description = \"All enabled questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All Enabled\",\n",
    "    definition = \"where enabled=1\",\n",
    "    description = \"All enabled questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All TF\",\n",
    "    definition = \"where type='True/False'\",\n",
    "    description = \"All True/False questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All Multiple Choice\",\n",
    "    definition = \"where type='Multiple Choice'\",\n",
    "    description = \"All True/False questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Questions\n",
    "### Example formatting a true/false question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The query (queries) will come from the test_definitions table\n",
    "query = \"select id from question_templates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select id, question, answer, correct, randomize, type, aota, nota\"\n",
    "query += \"from question_templates\" \n",
    "query += \"where id=1\"\n",
    "\n",
    "#query = \"select * from question_templates\"\n",
    "#query = \"select * from question_templates where id in (1,3)\"\n",
    "#query = \"select * from question_templates where type = 'Multiple Choice'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.execute(query).fetchall()\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(number = qnum, question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question fields\n",
    "questions = metadata.tables['questions']\n",
    "print(questions.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = questions.insert().values(\n",
    "    question = q,\n",
    "    answer = a, \n",
    "    item = qnum,\n",
    "    test_id = 0,\n",
    "    template_id = df['id'][w]\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'][w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example formatting a multiple choice question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1 \n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        number = qnum, \n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w]==1, \n",
    "        nota = df['nota'][w]==1)\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1\n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w], \n",
    "        nota = df['nota'][w])\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over multiple rows\n",
    "### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            number = w + 1, \n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            number = w + 1,\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = metadata.tables['questions']\n",
    "print(questions.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 5\n",
    "item = 1\n",
    "\n",
    "ins = questions.insert().values(\n",
    "    question = q,\n",
    "    answer = a, \n",
    "    item = item, \n",
    "    test_id = test_id, \n",
    "    template_id = df['id'][w]\n",
    ")\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## Save the seed in tests\n",
    "seed = random.randint(1,1e10)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_id = 99\n",
    "w = 0\n",
    "q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick import from Excel File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
