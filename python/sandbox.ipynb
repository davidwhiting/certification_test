{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_choice(question, choices, which=1, randomize=True, aota=False, \n",
    "    nota=False, none_prob=0.2, number=None):\n",
    "    \"\"\"\n",
    "    Create a multiple choice question randomizing order\n",
    "        number : question number on test (for formatting)\n",
    "        question : string\n",
    "        choices : list of string \n",
    "        which : which choice is correct (defaults to first in list)\n",
    "            if -1 then \"None of the above\" is correct and a correct answer \n",
    "                wasn't provided\n",
    "            if 0 then \"All of the above\" is correct \n",
    "        randomize : randomize order of options, making questions unique\n",
    "        aota : include \"All of the above\" as an option\n",
    "        nota : include \"None of the above\" as an option \n",
    "        none_prob : probability that \"None of the above\" is right (If a correct \n",
    "            answer is supplied, it will be removed with this probability.) \n",
    "\n",
    "\n",
    "    Note: \n",
    "       - \"All of the above\" always appears before \"None of the above\" in \n",
    "         options and after random shuffle\n",
    "       - If a correct answer is removed and the answer made \"None of the above\",\n",
    "         and there are only 3 remaining options, then \"All of the above\" will \n",
    "         also be added \n",
    "    \n",
    "    \"\"\"\n",
    "    import random\n",
    "    import string\n",
    "\n",
    "    AOTA = \"All of the above\"\n",
    "    NOTA = \"None of the above\"\n",
    "    \n",
    "    # Select right answer if given\n",
    "    if which > 0:\n",
    "        correct = choices[which-1]\n",
    "    elif which == 0:\n",
    "        correct = AOTA\n",
    "    else: # which == -1:\n",
    "        correct = NOTA\n",
    "        \n",
    "    # Randomize order of options before appending 'All ...' or 'None ...'\n",
    "    if randomize:\n",
    "        random.shuffle(choices)\n",
    "\n",
    "    # Append 'All of the above'\n",
    "    if aota or which == 0 :\n",
    "        choices.append(AOTA)\n",
    "\n",
    "    # Append 'None of the above'\n",
    "    if nota or which == -1:\n",
    "        choices.append(NOTA)\n",
    "\n",
    "    # Remove the correct answer with probability none_prob\n",
    "    if which > 0 and nota and none_prob > 0:\n",
    "        if random.random() <= none_prob:\n",
    "            choices.remove(correct)\n",
    "            correct = NOTA\n",
    "            # if not enough options after removing the correct answer, add ALL\n",
    "            if (not aota) and len(choices) <= 4:\n",
    "                choices.insert(len(choices)-1, AOTA)\n",
    "    \n",
    "    # get correct answer\n",
    "    answer = string.ascii_lowercase[choices.index(correct)]\n",
    "\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "\n",
    "    # Format the question with options                \n",
    "    for i, choice in enumerate(choices):\n",
    "        question += blank + string.ascii_lowercase[i] + \") \" + choice\n",
    "\n",
    "    return question, answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_true_false(question, answer, number=None):\n",
    "    \"\"\"\n",
    "    Format a True/False question\n",
    "    \"\"\"\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "        \n",
    "    question += blank + \"a) True\"\n",
    "    question += blank + \"b) False\"\n",
    "\n",
    "    if answer.lower() in ['t', 'true']:\n",
    "        answer = \"a\"\n",
    "    else:\n",
    "        answer = \"b\"\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query MySQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = db.create_engine('mysql://root:root@127.0.0.1:8306/certification')\n",
    "engine = db.create_engine('mysql://root:root@127.0.0.1:8889/certification')\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MetaData instance\n",
    "metadata = db.MetaData()\n",
    "\n",
    "# reflect db schma to MetaData\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "\n",
    "#engine = db.create_engine('mysql://root:root@127.0.0.1:8306/certification')\n",
    "engine = db.create_engine('mysql://root:root@127.0.0.1:8889/certification')\n",
    "conn = engine.connect()\n",
    "\n",
    "# Create a MetaData instance\n",
    "metadata = db.MetaData()\n",
    "\n",
    "# reflect db schma to MetaData\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from question_templates\"\n",
    "#query = \"select * from question_templates where id in (1,3)\"\n",
    "#query = \"select * from question_templates where type = 'Multiple Choice'\"\n",
    "\n",
    "result = conn.execute(query).fetchall()\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>tags</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Recipes need to be added to Driverless AI each...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-06 05:31:34</td>\n",
       "      <td>2020-05-06 05:31:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-06 05:31:34</td>\n",
       "      <td>2020-05-06 05:31:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0   1  Recipes need to be added to Driverless AI each...   \n",
       "1   2  Which graph will show your variables which cou...   \n",
       "\n",
       "                                              answer  correct  randomize  \\\n",
       "0                                              False        1          1   \n",
       "1  [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...        1          1   \n",
       "\n",
       "              type  tags  aota  nota  epsilon  enabled          created_at  \\\n",
       "0       True/False  Easy     0     0   0.0001        0 2020-05-06 05:31:34   \n",
       "1  Multiple Choice  None     0     0   0.0001        0 2020-05-06 05:31:34   \n",
       "\n",
       "        last_modified  \n",
       "0 2020-05-06 05:31:34  \n",
       "1 2020-05-06 05:31:34  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example formatting a true/false question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "   a) True\n",
      "   b) False\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(number = qnum, question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "a) True\n",
      "b) False\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example formatting a multiple choice question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "   a) Spikey Histograms\n",
      "   b) Skewed Histograms\n",
      "   c) Outliers\n",
      "   d) Correlation Graph\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "w = 1 \n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        number = qnum, \n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w]==1, \n",
    "        nota = df['nota'][w]==1)\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "a) Correlation Graph\n",
      "b) Spikey Histograms\n",
      "c) Skewed Histograms\n",
      "d) Outliers\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "w=1\n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w], \n",
    "        nota = df['nota'][w])\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over multiple rows\n",
    "### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. For regression problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "   a) Cluster\n",
      "   b) Random\n",
      "   c) Systematic\n",
      "   d) Stratified\n",
      "b\n",
      "\n",
      "\n",
      "2. Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "   a) True\n",
      "   b) False\n",
      "b\n",
      "\n",
      "\n",
      "3. Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "   a) Correlation Graph\n",
      "   b) Spikey Histograms\n",
      "   c) Skewed Histograms\n",
      "   d) Outliers\n",
      "c\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            number = w + 1, \n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            number = w + 1,\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regression problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "a) Cluster\n",
      "b) Systematic\n",
      "c) Random\n",
      "d) Stratified\n",
      "c\n",
      "\n",
      "\n",
      "Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "a) True\n",
      "b) False\n",
      "b\n",
      "\n",
      "\n",
      "Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "a) Outliers\n",
      "b) Correlation Graph\n",
      "c) Skewed Histograms\n",
      "d) Spikey Histograms\n",
      "c\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_templates', 'questions']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'question', 'answer', 'item', 'test_id', 'template_id']\n"
     ]
    }
   ],
   "source": [
    "questions = metadata.tables['questions']\n",
    "print(questions.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x12a05da90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = 5\n",
    "item = 1\n",
    "\n",
    "ins = questions.insert().values(\n",
    "    question = q,\n",
    "    answer = a, \n",
    "    item = item, \n",
    "    test_id = test_id, \n",
    "    template_id = df['id'][w]\n",
    ")\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1563586409"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "## Save the seed in tests\n",
    "seed = random.randint(1,1e10)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ee9933a6c5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m q, a = make_multiple_choice(\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mchoices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_id = 99\n",
    "w = 0\n",
    "q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-16a3a5caaaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regression problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "a) Cluster\n",
      "b) Stratified\n",
      "c) Random\n",
      "d) Systematic\n",
      "e) None of the above\n",
      "c\n",
      "\n",
      "\n",
      "Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "a) True\n",
      "b) False\n",
      "b\n",
      "\n",
      "\n",
      "Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "a) Skewed Histograms\n",
      "b) Spikey Histograms\n",
      "c) Outliers\n",
      "d) Correlation Graph\n",
      "e) None of the above\n",
      "a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regression problems, which type of sampling will Driverless AI perform at the start of an experiment?\n",
      "a) Cluster\n",
      "b) Stratified\n",
      "c) Random\n",
      "d) Systematic\n",
      "e) None of the above\n",
      "c\n",
      "\n",
      "\n",
      "Recipes need to be added to Driverless AI each time you want to use it for an experiment.\n",
      "a) True\n",
      "b) False\n",
      "b\n",
      "\n",
      "\n",
      "Which graph will show your variables which could be good candidates for transformation before being used in modeling?\n",
      "a) Skewed Histograms\n",
      "b) Spikey Histograms\n",
      "c) Outliers\n",
      "d) Correlation Graph\n",
      "e) None of the above\n",
      "a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick import from Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylightxl as xl\n",
    "db = xl.readxl('Questions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheet1']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.ws_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.ws('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1037, 8]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graphs shown on the AutoVisualization page are the same for all datasets'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.address('A3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question Text',\n",
       " 'Answers set (multiple choice / checkbox / matching / true-false)',\n",
       " 'Correct',\n",
       " 'Randomize',\n",
       " 'Type',\n",
       " 'Tags',\n",
       " 'Difficulty (optional)',\n",
       " 'Contributor']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.row(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graphs shown on the AutoVisualization page are the same for all datasets'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = 3\n",
    "# Question\n",
    "db.index(row=r, col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The graphs shown on the AutoVisualization page are the same for all datasets',\n",
       " '\"False\"',\n",
       " '',\n",
       " '',\n",
       " 'True/False',\n",
       " '\"AutoViz\"',\n",
       " '',\n",
       " 'Chemere Davis']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.row(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.ws('Sheet1').index(row=1,col=1)\n",
    "\n",
    "db.ws('Sheet1').row(1)\n",
    "db.ws('Sheet1').col(1)\n",
    "\n",
    "for row in db.ws('Sheet1').rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets',\n",
       " 'exp_definitions',\n",
       " 'experiments',\n",
       " 'question_templates',\n",
       " 'questions',\n",
       " 'results',\n",
       " 'student_answers',\n",
       " 'students',\n",
       " 'tag_list',\n",
       " 'tags',\n",
       " 'test_definitions',\n",
       " 'tests']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'question', 'answer', 'correct', 'randomize', 'type', 'tags', 'aota', 'nota', 'epsilon', 'enabled', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "templates = metadata.tables['question_templates']\n",
    "print(templates.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = db.row(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True/False'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = templates.insert().values(\n",
    "    question = raw[0],\n",
    "    answer = raw[1], \n",
    "    correct = raw[2], \n",
    "    randomize = raw[3], \n",
    "    type = raw[4],\n",
    "    template_id = df['id'][w]\n",
    ")\n",
    "\n",
    "conn.execute(ins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
