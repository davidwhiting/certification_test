{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Quick and dirty functions to create unique randomized tests. These can be improved, right now they are just scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multiple_choice(question, choices, which=1, randomize=True, aota=False, \n",
    "    nota=False, none_prob=0.2, number=None):\n",
    "    \"\"\"\n",
    "    Create a multiple choice question randomizing order\n",
    "        number : question number on test (for formatting)\n",
    "        question : string\n",
    "        choices : list of string \n",
    "        which : which choice is correct (defaults to first in list)\n",
    "            if -1 then \"None of the above\" is correct and a correct answer \n",
    "                wasn't provided\n",
    "            if 0 then \"All of the above\" is correct \n",
    "        randomize : randomize order of options, making questions unique\n",
    "        aota : include \"All of the above\" as an option\n",
    "        nota : include \"None of the above\" as an option \n",
    "        none_prob : probability that \"None of the above\" is right (If a correct \n",
    "            answer is supplied, it will be removed with this probability.) \n",
    "\n",
    "\n",
    "    Note: \n",
    "       - \"All of the above\" always appears before \"None of the above\" in \n",
    "         options and after random shuffle\n",
    "       - If a correct answer is removed and the answer made \"None of the above\",\n",
    "         and there are only 3 remaining options, then \"All of the above\" will \n",
    "         also be added \n",
    "    \n",
    "    \"\"\"\n",
    "    import random\n",
    "    import string\n",
    "\n",
    "    AOTA = \"All of the above\"\n",
    "    NOTA = \"None of the above\"\n",
    "    \n",
    "    # Select right answer if given\n",
    "    if which > 0:\n",
    "        correct = choices[which-1]\n",
    "    elif which == 0:\n",
    "        correct = AOTA\n",
    "    else: # which == -1:\n",
    "        correct = NOTA\n",
    "        \n",
    "    # Randomize order of options before appending 'All ...' or 'None ...'\n",
    "    if randomize:\n",
    "        random.shuffle(choices)\n",
    "\n",
    "    # Append 'All of the above'\n",
    "    if aota or which == 0 :\n",
    "        choices.append(AOTA)\n",
    "\n",
    "    # Append 'None of the above'\n",
    "    if nota or which == -1:\n",
    "        choices.append(NOTA)\n",
    "\n",
    "    # Remove the correct answer with probability none_prob\n",
    "    if which > 0 and nota and none_prob > 0:\n",
    "        if random.random() <= none_prob:\n",
    "            choices.remove(correct)\n",
    "            correct = NOTA\n",
    "            # if not enough options after removing the correct answer, add ALL\n",
    "            if (not aota) and len(choices) <= 4:\n",
    "                choices.insert(len(choices)-1, AOTA)\n",
    "    \n",
    "    # get correct answer\n",
    "    answer = string.ascii_lowercase[choices.index(correct)]\n",
    "\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "\n",
    "    # Format the question with options                \n",
    "    for i, choice in enumerate(choices):\n",
    "        question += blank + string.ascii_lowercase[i] + \") \" + str(choice)\n",
    "\n",
    "    return question, answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_true_false(question, answer, number=None):\n",
    "    \"\"\"\n",
    "    Format a True/False question\n",
    "    \"\"\"\n",
    "\n",
    "    # format if number present\n",
    "    if number is None:\n",
    "        blank = \"\\n\"\n",
    "    else:\n",
    "        # format the question\n",
    "        if(number > 9):\n",
    "            blank = \"\\n    \"\n",
    "        else:\n",
    "            blank = \"\\n   \"\n",
    "        \n",
    "        question = str(number) + \". \" + question\n",
    "        \n",
    "    question += blank + \"a) True\"\n",
    "    question += blank + \"b) False\"\n",
    "\n",
    "    if answer.lower() in ['t', 'true']:\n",
    "        answer = \"a\"\n",
    "    else:\n",
    "        answer = \"b\"\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_question_templates(raw):\n",
    "    \"\"\"\n",
    "    Helper code to save questions imported from the xlsx file into the question_templates table of the database\n",
    "    \n",
    "    This basically has no error checking, and assumes that the line\n",
    "        templates = metadata.tables['question_templates']  \n",
    "    has been run beforehand\n",
    "    \n",
    "    \"\"\"\n",
    "    # If empty, set to database default\n",
    "    if raw[2] == '':   \n",
    "        correct = 1\n",
    "    else:\n",
    "        correct = raw[2]\n",
    "\n",
    "    if raw[3] == '':\n",
    "        randomize = 1\n",
    "    else:\n",
    "        randomize = raw[3]\n",
    "\n",
    "    ins = templates.insert().values(\n",
    "        question = raw[0],\n",
    "        answer = raw[1], \n",
    "        correct = correct, \n",
    "        randomize = randomize, \n",
    "        type = raw[4],\n",
    "        comments = 'labels: ' + raw[5] + '; author: ' + raw[7] \n",
    "    )\n",
    "\n",
    "    conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_list(query, n=None, randomize=True, as_text=False):\n",
    "    \"\"\"\n",
    "    Retrieves a list of id's from the question template table\n",
    "    Alternatively randomize them\n",
    "    \"\"\"\n",
    "    result = conn.execute(query).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "    id = df['id'].to_list()\n",
    "    \n",
    "    if (n is None) or (n == 0):\n",
    "        n = len(id)\n",
    "    # if randomizing order of questions\n",
    "    if randomize:\n",
    "        id = random.sample(id, n)\n",
    "    else:\n",
    "        id = id[0:n]\n",
    "        \n",
    "    # return as a text object to store in database\n",
    "    if as_text:\n",
    "        id = \"(\" + ', '.join(map(str, id)) + \")\"\n",
    "\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_by_name(name):\n",
    "    \"\"\"\n",
    "    Select queries from a test and execute them\n",
    "    \n",
    "    Need to add error checking, etc. into this to make it work.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## using the text() object to execute across multiple tables\n",
    "    sql = \"\"\"\n",
    "    SELECT b.id, a.section, CONCAT(a.prefix, a.definition) AS query, a.randomize, a.n \n",
    "    FROM test_subqueries a, test_definitions b \n",
    "    WHERE a.definition_id=b.id AND b.name= :name\n",
    "    \"\"\"\n",
    "\n",
    "    result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "    \n",
    "    result = []\n",
    "    for i, query in enumerate(df['query']):\n",
    "        tmp = get_id_list( df['query'][i], n=df['n'][i], randomize=df['randomize'][i] )\n",
    "        result = result + tmp # concatenate lists\n",
    "    \n",
    "    result = \"(\" + ', '.join(map(str, result)) + \")\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_number(name):\n",
    "    \"\"\"\n",
    "    Select id number from a test described by :name\n",
    "    \"\"\"\n",
    "    ## using the text() object to execute across multiple tables\n",
    "    sql = \"\"\"\n",
    "        SELECT id FROM test_definitions b WHERE name= :name\n",
    "        \"\"\"\n",
    "    result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "\n",
    "    return df['id'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MySQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "\n",
    "engine = db.create_engine('mysql://root:root@127.0.0.1:8306/certification')\n",
    "#engine = db.create_engine('mysql://root:root@127.0.0.1:8889/certification')\n",
    "conn = engine.connect()\n",
    "\n",
    "# Create a MetaData instance\n",
    "metadata = db.MetaData()\n",
    "\n",
    "# reflect db schma to MetaData\n",
    "metadata.reflect(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select * from question_templates\"\n",
    "#query = \"select * from question_templates where id in (1,3)\"\n",
    "#query = \"select * from question_templates where type = 'Multiple Choice'\"\n",
    "\n",
    "result = conn.execute(query).fetchall()\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 19:23:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show the variables that could...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 19:24:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 19:24:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>By default, correlation scatterplots are inclu...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 19:25:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 19:25:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-26 16:46:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-26 14:00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>Multiclass classification is possible in Drive...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-26 16:48:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>Multi-label classification is supported in Dri...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-26 16:50:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>How can one reduce the size of a MOJO?</td>\n",
       "      <td>[\"Reduce accuracy\", \"Increase interpretibility...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: [\"Scoring Pipeline\", \"Experiments\"]; a...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-26 16:51:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show the variables that could...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  By default, correlation scatterplots are inclu...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106  How are the final scoring pipelines ensembles ...   \n",
       "106  107  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "107  108  Multiclass classification is possible in Drive...   \n",
       "108  109  Multi-label classification is supported in Dri...   \n",
       "109  110             How can one reduce the size of a MOJO?   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"      NaN        NaN   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...      1.0        1.0   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...      1.0        1.0   \n",
       "3                 [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"]      1.0        0.0   \n",
       "4                                               \"True\"      NaN        NaN   \n",
       "..                                                 ...      ...        ...   \n",
       "105  [\"stacked ensemble\", \"mean of the individual m...      1.0        1.0   \n",
       "106                                             \"True\"      NaN        NaN   \n",
       "107                                             \"True\"      NaN        NaN   \n",
       "108                                            \"False\"      NaN        NaN   \n",
       "109  [\"Reduce accuracy\", \"Increase interpretibility...      0.0        1.0   \n",
       "\n",
       "                type  aota  nota epsilon  enabled  \\\n",
       "0         True/False   NaN   NaN    None        1   \n",
       "1    Multiple Choice   0.0   1.0    None        1   \n",
       "2    Multiple Choice   0.0   1.0    None        1   \n",
       "3    Multiple Choice   0.0   0.0    None        1   \n",
       "4         True/False   NaN   NaN    None        1   \n",
       "..               ...   ...   ...     ...      ...   \n",
       "105  Multiple Choice   1.0   1.0    None        1   \n",
       "106       True/False   NaN   NaN    None        1   \n",
       "107       True/False   NaN   NaN    None        1   \n",
       "108       True/False   NaN   NaN    None        1   \n",
       "109  Multiple Choice   1.0   1.0    None        1   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                                    2020-05-06 13:41:05   \n",
       "109  labels: [\"Scoring Pipeline\", \"Experiments\"]; a... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-11 19:23:29  \n",
       "1   2020-05-11 19:24:07  \n",
       "2   2020-05-11 19:24:46  \n",
       "3   2020-05-11 19:25:32  \n",
       "4   2020-05-11 19:25:44  \n",
       "..                  ...  \n",
       "105 2020-05-26 16:46:58  \n",
       "106 2020-05-26 14:00:27  \n",
       "107 2020-05-26 16:48:51  \n",
       "108 2020-05-26 16:50:22  \n",
       "109 2020-05-26 16:51:55  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'description', 'dai_version', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "testdef = metadata.tables['test_definitions']\n",
    "print(testdef.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'definition_id', 'section', 'prefix', 'definition', 'n', 'randomize', 'created_at', 'last_modified']\n"
     ]
    }
   ],
   "source": [
    "subquery = metadata.tables['test_subqueries']\n",
    "print(subquery.columns.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below: Insert some test definitions manually (this only needs to be done once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "## Add an example test definition to the database\n",
    "\n",
    "ins = testdef.insert().values(\n",
    "    name = 'All',\n",
    "    description = \"All questions in database\", \n",
    "    )\n",
    "## Only needs to be done once\n",
    "#conn.execute(ins)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "## This query should always return only 1 result, \n",
    "## the id which we will pass to the subquery table for tests with multiple sections\n",
    "## (multiple sql queries to select test questions)\n",
    "\n",
    "query = \"select id from test_definitions where name='All'\"\n",
    "result = conn.execute(query).fetchall()\n",
    "id = result[0]['id']\n",
    "\n",
    "ins = subquery.insert().values(\n",
    "    definition_id = id,\n",
    "    randomize = False\n",
    "    )\n",
    "#conn.execute(ins)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "name = \"TF then MC\"\n",
    "ins = testdef.insert().values(\n",
    "    name = name,\n",
    "    description = \"First TF then MC\", \n",
    "    )\n",
    "conn.execute(ins)\n",
    "\n",
    "## This query should always return only 1 result\n",
    "query = \"select id from test_definitions where name='\" + name + \"'\"\n",
    "result = conn.execute(query).fetchall()\n",
    "id = result[0]['id']\n",
    "\n",
    "statements = [\"where type='True/False'\", \"where type='Multiple Choice'\"]\n",
    "\n",
    "for i, query in enumerate(statements):\n",
    "    ins = subquery.insert().values(\n",
    "        definition_id = id,\n",
    "        section = i+1, \n",
    "        definition = query,\n",
    "        randomize = False\n",
    "    )\n",
    "    conn.execute(ins)   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to automate the above with some code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test from test definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import text\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>section</th>\n",
       "      <th>query</th>\n",
       "      <th>randomize</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>SELECT id FROM question_templates where type='...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SELECT id FROM question_templates where type='...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  section                                              query  randomize  \\\n",
       "0   2        1  SELECT id FROM question_templates where type='...          0   \n",
       "1   2        2  SELECT id FROM question_templates where type='...          0   \n",
       "\n",
       "   n  \n",
       "0  0  \n",
       "1  0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"TF then MC\"\n",
    "\n",
    "## using the text() object to execute across multiple tables\n",
    "sql = \"\"\"\n",
    "   SELECT b.id, a.section, CONCAT(a.prefix, a.definition) AS query, a.randomize, a.n \n",
    "   FROM test_subqueries a, test_definitions b \n",
    "   WHERE a.definition_id=b.id AND b.name= :name\n",
    "   \"\"\"\n",
    "result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = get_queries_by_name(\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = get_queries_by_name(\"TF then MC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1, 5, 8, 9, 11, 14, 17, 18, 20, 21, 23, 29, 30, 31, 32, 34, 41, 42, 48, 49, 50, 51, 61, 62, 64, 65, 66, 68, 69, 76, 77, 78, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 101, 103, 104, 105, 107, 108, 109, 2, 3, 4, 6, 7, 10, 12, 13, 15, 16, 19, 22, 24, 25, 26, 27, 28, 33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 63, 67, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 83, 90, 99, 100, 102, 106, 110)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the result to the tests table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using the text() object to execute across multiple tables\n",
    "sql = \"\"\"\n",
    "SELECT id FROM test_definitions b WHERE name= :name\n",
    "\"\"\"\n",
    "result = conn.execute(text(sql), name=Name).fetchall()\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "\n",
    "df['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    result = []\n",
    "    for i, query in enumerate(df['query']):\n",
    "        tmp = get_id_list( df['query'][i], n=df['n'][i], randomize=df['randomize'][i] )\n",
    "        result = result + tmp # concatenate lists\n",
    "    \n",
    "    result = \"(\" + ', '.join(map(str, result)) + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'definition_id', 'seed', 'question_list', 'experiments', 'none_prob', 'created_at']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x11ee04c18>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = metadata.tables['tests']\n",
    "print(tests.columns.keys())\n",
    "\n",
    "# generate random seed\n",
    "seed = random.randrange(sys.maxsize)\n",
    "# get question list\n",
    "result = get_queries_by_name(\"TF then MC\")\n",
    "definition_id = get_test_number(\"TF then MC\")\n",
    "\n",
    "ins = tests.insert().values(\n",
    "    definition_id = definition_id,\n",
    "    seed = seed,\n",
    "    question_list = result\n",
    "    )\n",
    "conn.execute(ins)\n",
    "\n",
    "## Create a new test from the tests table\n",
    "\n",
    "### Populates the Questions table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Test\n",
    "\n",
    "We are going to iterate over the `questions` and\n",
    "1. pull a template from the `question_template` table,\n",
    "2. create the question text and the answer, and\n",
    "3. save the information back to the `questions` table.\n",
    "\n",
    "The multiple communication cycles between MySQL and Python are slightly inefficient, but very straightforward. The inefficiency here is irrelevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 2\n",
    "\n",
    "query = \"select id, seed, question_list, experiments, none_prob from tests where id=:id\"\n",
    "result = conn.execute(text(query), id=test_id).fetchall()\n",
    "\n",
    "# Retrieve experiment information\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "\n",
    "seed = df['seed'][0]\n",
    "question_list = df['question_list'][0]\n",
    "experiments = df['experiments'][0]\n",
    "none_prob = df['none_prob'][0]\n",
    "\n",
    "# create list from database question_list string\n",
    "ql = question_list[1:-1].split(\",\")\n",
    "question_list = [int(i) for i in ql]\n",
    "\n",
    "# question table where questions and answers will be entered\n",
    "questions = metadata.tables['questions']\n",
    "\n",
    "# general query for retrieving question templates from db\n",
    "query = \"select * from question_templates where id=:id\"\n",
    "sql = text(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed from database\n",
    "random.seed(seed)\n",
    "\n",
    "update_database = False\n",
    "Results = \"\"\n",
    "\n",
    "# loop over all questions to create test\n",
    "for i, id in enumerate(question_list):\n",
    "\n",
    "    result = conn.execute(sql, id=id).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "\n",
    "    if df['enabled'][0]:\n",
    "        \n",
    "        if df['type'][0] == 'True/False':\n",
    "            q, a = make_true_false(df['question'][0], df['answer'][0])\n",
    "        elif df['type'][0] == 'Multiple Choice':\n",
    "            q, a = make_multiple_choice(df['question'][0], eval(df['answer'][0]), \n",
    "                                    which=df['correct'][0], randomize=df['randomize'][0],\n",
    "                                    aota=df['aota'][0], nota=df['nota'][0], none_prob=none_prob)\n",
    "        else:\n",
    "            # Gently exit... replace below with better code\n",
    "            q = \"\"\n",
    "            a = \"\"\n",
    "            \n",
    "        if update_database:\n",
    "            conn.execute(insert_sql,\n",
    "                question = q,\n",
    "                answer = a, \n",
    "                number = i + 1,\n",
    "                test_id = test_id,\n",
    "                template_id = id\n",
    "                )\n",
    "        else:\n",
    "            Results += \"\\n\\n\" + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert or Update on Duplicate statement\n",
    "insert_stmt = \"\"\"\n",
    "        insert into questions (question, answer, number, test_id, template_id) \n",
    "        values (:question, :answer, :number, :test_id, :template_id) \n",
    "        on duplicate key update\n",
    "          question = :question,\n",
    "          answer = :answer,\n",
    "          number = :number,\n",
    "          test_id = :test_id,\n",
    "          template_id = :template_id\n",
    "        \"\"\"\n",
    "\n",
    "insert_sql = text(insert_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_test = Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ins = questions.insert().values(\n",
    "#            question = q,\n",
    "#            answer = a, \n",
    "#            number = i + 1,\n",
    "#            test_id = test_id,\n",
    "#            template_id = id) \n",
    "\n",
    "#conn.execute(text(stmt), question=\"YES!\", answer=\"\", number=51, test_id=1, template_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed from database\n",
    "random.seed(seed)\n",
    "\n",
    "# loop over all questions to create test\n",
    "for i, id in enumerate(question_list):\n",
    "\n",
    "    result = conn.execute(sql, id=id).fetchall()\n",
    "    df = pd.DataFrame(result)\n",
    "    df.columns = result[0].keys()\n",
    "\n",
    "    if df['enabled'][0]:\n",
    "        \n",
    "        if df['type'][0] == 'True/False':\n",
    "            q, a = make_true_false(df['question'][0], df['answer'][0])\n",
    "        elif df['type'][0] == 'Multiple Choice':\n",
    "            q, a = make_multiple_choice(df['question'][0], eval(df['answer'][0]), \n",
    "                                    which=df['correct'][0], randomize=df['randomize'][0],\n",
    "                                    aota=df['aota'][0], nota=df['nota'][0], none_prob=none_prob)\n",
    "        else:\n",
    "            # Gently exit... replace below with better code\n",
    "            q = \"\"\n",
    "            a = \"\"\n",
    "\n",
    "        \n",
    "        ins = questions.insert().values(\n",
    "            question = q,\n",
    "            answer = a, \n",
    "            number = i + 1,\n",
    "            test_id = test_id,\n",
    "            template_id = id\n",
    "            )\n",
    "    \n",
    "        conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"select * from question_templates where id=:id\"\n",
    "#sql = text(query)\n",
    "\n",
    "#result = conn.execute(text(query), id=1).fetchall()\n",
    "\n",
    "#query = \"select question, answer, correct, randomize, type, aota, nota, epsilon, enabled from question_templates where id in \" + question_list\n",
    "\n",
    "#result = conn.execute(query).fetchall()\n",
    "#df = pd.DataFrame(result)\n",
    "#df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Correlation scatterplots are included for any ...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Kiri Nichol</td>\n",
       "      <td>Is the final scoring pipeline always an ensamb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True/False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>Can I do multi-label classification in Driverl...</td>\n",
       "      <td>Is multi-class classification supported?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: How do I reduce the size of the MOJO?;...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show your variables which cou...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  Correlation scatterplots are included for any ...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106                                        Kiri Nichol   \n",
       "106  107  How are the final scoring pipelines ensembles ...   \n",
       "107  108  [\"stacked ensemble\", \"mean of the individual m...   \n",
       "108  109  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "109  110  Can I do multi-label classification in Driverl...   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"        1          1   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...        1          1   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...        1          1   \n",
       "3                  [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"        1          0   \n",
       "4                                               \"True\"        1          1   \n",
       "..                                                 ...      ...        ...   \n",
       "105  Is the final scoring pipeline always an ensamb...        1          1   \n",
       "106                                             \"True\"        1          1   \n",
       "107                                            \"False\"        1          1   \n",
       "108                                             \"True\"        1          1   \n",
       "109           Is multi-class classification supported?        0          1   \n",
       "\n",
       "                type  aota  nota  epsilon  enabled  \\\n",
       "0         True/False     0     0   0.0001        0   \n",
       "1    Multiple Choice     0     0   0.0001        0   \n",
       "2    Multiple Choice     0     0   0.0001        0   \n",
       "3    Multiple Choice     0     0   0.0001        0   \n",
       "4         True/False     0     0   0.0001        0   \n",
       "..               ...   ...   ...      ...      ...   \n",
       "105  Multiple Choice     0     0   0.0001        0   \n",
       "106       True/False     0     0   0.0001        0   \n",
       "107       True/False     0     0   0.0001        0   \n",
       "108       True/False     0     0   0.0001        0   \n",
       "109  Multiple Choice     0     0   0.0001        0   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "109  labels: How do I reduce the size of the MOJO?;... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-06 13:41:05  \n",
       "1   2020-05-06 13:41:05  \n",
       "2   2020-05-06 13:41:05  \n",
       "3   2020-05-06 13:41:05  \n",
       "4   2020-05-06 13:41:05  \n",
       "..                  ...  \n",
       "105 2020-05-06 13:41:05  \n",
       "106 2020-05-06 13:41:05  \n",
       "107 2020-05-06 13:41:05  \n",
       "108 2020-05-06 13:41:05  \n",
       "109 2020-05-06 13:41:05  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which graph will show your variables that could be good candidates for transformation before being used in modeling?\n",
      "a) Spikey Histograms\n",
      "b) Skewed Histograms\n",
      "c) Outliers\n",
      "d) Correlation Graph\n",
      "e) None of the above\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1778253695752227620"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "      <th>randomize</th>\n",
       "      <th>type</th>\n",
       "      <th>aota</th>\n",
       "      <th>nota</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>enabled</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The graphs shown on the AutoVisualization page...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:50:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which graph will show your variables which cou...</td>\n",
       "      <td>[\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The ______ plot will indicate variables with a...</td>\n",
       "      <td>[\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: Chemere Davis</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Correlation scatterplots are included for any ...</td>\n",
       "      <td>[\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Skewed histograms are presented in descending ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: \"AutoViz\"; author: David Engler</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Kiri Nichol</td>\n",
       "      <td>Is the final scoring pipeline always an ensamb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>107</td>\n",
       "      <td>How are the final scoring pipelines ensembles ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>108</td>\n",
       "      <td>[\"stacked ensemble\", \"mean of the individual m...</td>\n",
       "      <td>\"False\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>MOJOs are thread-safe and an instance of MOJO ...</td>\n",
       "      <td>\"True\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True/False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: ; author:</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-11 14:49:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>110</td>\n",
       "      <td>Can I do multi-label classification in Driverl...</td>\n",
       "      <td>Is multi-class classification supported?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multiple Choice</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>labels: How do I reduce the size of the MOJO?;...</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "      <td>2020-05-06 13:41:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0      1  The graphs shown on the AutoVisualization page...   \n",
       "1      2  Which graph will show your variables which cou...   \n",
       "2      3  The ______ plot will indicate variables with a...   \n",
       "3      4  Correlation scatterplots are included for any ...   \n",
       "4      5  Skewed histograms are presented in descending ...   \n",
       "..   ...                                                ...   \n",
       "105  106                                        Kiri Nichol   \n",
       "106  107  How are the final scoring pipelines ensembles ...   \n",
       "107  108  [\"stacked ensemble\", \"mean of the individual m...   \n",
       "108  109  MOJOs are thread-safe and an instance of MOJO ...   \n",
       "109  110  Can I do multi-label classification in Driverl...   \n",
       "\n",
       "                                                answer  correct  randomize  \\\n",
       "0                                              \"False\"      NaN        NaN   \n",
       "1    [\"Skewed Histograms\", \"Outliers\", \"Spikey Hist...      1.0        1.0   \n",
       "2    [\"Outlier\", \"Biplot\", \"Data Heatmap\", \"Recomme...      1.0        1.0   \n",
       "3                  [\"0.95\",\"0.90\",\"0.85\",\"0.80\",\"0.75\"      1.0        0.0   \n",
       "4                                               \"True\"      NaN        NaN   \n",
       "..                                                 ...      ...        ...   \n",
       "105  Is the final scoring pipeline always an ensamb...      1.0        1.0   \n",
       "106                                             \"True\"      NaN        NaN   \n",
       "107                                            \"False\"      NaN        NaN   \n",
       "108                                             \"True\"      NaN        NaN   \n",
       "109           Is multi-class classification supported?      0.0        1.0   \n",
       "\n",
       "                type  aota  nota  epsilon  enabled  \\\n",
       "0         True/False   NaN   NaN      NaN        1   \n",
       "1    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "2    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "3    Multiple Choice   0.0   0.0   0.0001        0   \n",
       "4         True/False   NaN   NaN      NaN        0   \n",
       "..               ...   ...   ...      ...      ...   \n",
       "105  Multiple Choice   0.0   0.0   0.0001        0   \n",
       "106       True/False   NaN   NaN      NaN        0   \n",
       "107       True/False   NaN   NaN      NaN        0   \n",
       "108       True/False   NaN   NaN      NaN        0   \n",
       "109  Multiple Choice   0.0   0.0   0.0001        0   \n",
       "\n",
       "                                              comments          created_at  \\\n",
       "0             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "1             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "2             labels: \"AutoViz\"; author: Chemere Davis 2020-05-06 13:41:05   \n",
       "3              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "4              labels: \"AutoViz\"; author: David Engler 2020-05-06 13:41:05   \n",
       "..                                                 ...                 ...   \n",
       "105                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "106                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "107                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "108                                 labels: ; author:  2020-05-06 13:41:05   \n",
       "109  labels: How do I reduce the size of the MOJO?;... 2020-05-06 13:41:05   \n",
       "\n",
       "          last_modified  \n",
       "0   2020-05-11 14:50:06  \n",
       "1   2020-05-06 13:41:05  \n",
       "2   2020-05-06 13:41:05  \n",
       "3   2020-05-06 13:41:05  \n",
       "4   2020-05-11 14:49:14  \n",
       "..                  ...  \n",
       "105 2020-05-06 13:41:05  \n",
       "106 2020-05-11 14:49:14  \n",
       "107 2020-05-11 14:49:14  \n",
       "108 2020-05-11 14:49:14  \n",
       "109 2020-05-06 13:41:05  \n",
       "\n",
       "[110 rows x 13 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 14,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 23,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 41,\n",
       " 42,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 61,\n",
       " 62,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 68,\n",
       " 69,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 84,\n",
       " 85,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 101,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 63,\n",
       " 67,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 86,\n",
       " 90,\n",
       " 92,\n",
       " 95,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 106,\n",
       " 110]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over questions to create a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['type'][i] == 'True/False':\n",
    "    q, a = make_true_false(df['question'][i], df['answer'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graphs shown on the AutoVisualization page are the same for all datasets.\n",
      "a) True\n",
      "b) False\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  50,  51,  52,   1,  53,  54,   2,   3,  55,   4,  56,  57,\n",
       "         5,  58,  59,   6,   7,  60,   8,   9,  61,  10,  62,  63,  64,\n",
       "        65,  66,  11,  12,  13,  14,  15,  16,  67,  68,  69,  70,  71,\n",
       "        72,  17,  18,  73,  74,  75,  76,  77,  19,  20,  78,  21,  79,\n",
       "        80,  81,  82,  83,  84,  85,  86,  87,  22,  23,  88,  24,  25,\n",
       "        26,  89,  27,  28,  90,  91,  92,  93,  94,  95,  29,  30,  31,\n",
       "        96,  97,  98,  99, 100,  32,  33, 101,  34,  35,  36, 102,  37,\n",
       "       103,  38,  39, 104,  40,  41,  42, 105, 106,  43, 107,  44,  45,\n",
       "        46, 108,  47,  48,  49, 109])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argsort(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['randomize'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "shuffle(df['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()\n",
    "\n",
    "mystring = \"(\" + df['id'].to_csv(header=False, index=False, line_terminator=\", \")[:-2] + \")\"\n",
    "mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.execute(query).fetchall()\n",
    "\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testquery.insert().values(\n",
    "    name = \"All Enabled\",\n",
    "    definition = \"where enabled=1\",\n",
    "    description = \"All enabled questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All Enabled\",\n",
    "    definition = \"where enabled=1\",\n",
    "    description = \"All enabled questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All TF\",\n",
    "    definition = \"where type='True/False'\",\n",
    "    description = \"All True/False questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = testdef.insert().values(\n",
    "    name = \"All Multiple Choice\",\n",
    "    definition = \"where type='Multiple Choice'\",\n",
    "    description = \"All True/False questions in database\", \n",
    "    randomize = False\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Questions\n",
    "### Example formatting a true/false question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The query (queries) will come from the test_definitions table\n",
    "query = \"select id from question_templates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select id, question, answer, correct, randomize, type, aota, nota\"\n",
    "query += \"from question_templates\" \n",
    "query += \"where id=1\"\n",
    "\n",
    "#query = \"select * from question_templates\"\n",
    "#query = \"select * from question_templates where id in (1,3)\"\n",
    "#query = \"select * from question_templates where type = 'Multiple Choice'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = conn.execute(query).fetchall()\n",
    "df = pd.DataFrame(result)\n",
    "df.columns = result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(number = qnum, question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question fields\n",
    "questions = metadata.tables['questions']\n",
    "print(questions.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = questions.insert().values(\n",
    "    question = q,\n",
    "    answer = a, \n",
    "    item = qnum,\n",
    "    test_id = 0,\n",
    "    template_id = df['id'][w]\n",
    "    )\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'][w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnum = 1\n",
    "w = 0\n",
    "q, a = make_true_false(question = df['question'][w], answer = df['answer'][w])\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example formatting a multiple choice question\n",
    "#### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1 \n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        number = qnum, \n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w]==1, \n",
    "        nota = df['nota'][w]==1)\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1\n",
    "qnum = 5\n",
    "q, a = make_multiple_choice(\n",
    "        question = df['question'][w],\n",
    "        choices = eval(df['answer'][w]),\n",
    "        which = df['correct'][w],\n",
    "        randomize = df['randomize'][w],\n",
    "        aota = df['aota'][w], \n",
    "        nota = df['nota'][w])\n",
    "\n",
    "print(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over multiple rows\n",
    "### With numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            number = w + 1, \n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            number = w + 1,\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = metadata.tables['questions']\n",
    "print(questions.columns.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = 5\n",
    "item = 1\n",
    "\n",
    "ins = questions.insert().values(\n",
    "    question = q,\n",
    "    answer = a, \n",
    "    item = item, \n",
    "    test_id = test_id, \n",
    "    template_id = df['id'][w]\n",
    ")\n",
    "\n",
    "conn.execute(ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## Save the seed in tests\n",
    "seed = random.randint(1,1e10)\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_id = 99\n",
    "w = 0\n",
    "q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = df['nota'][w]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w, id in enumerate(df['id']): \n",
    "\n",
    "    if df['type'][w] == 'Multiple Choice':\n",
    "        q, a = make_multiple_choice(\n",
    "            question = df['question'][w],\n",
    "            choices = eval(df['answer'][w]),\n",
    "            which = df['correct'][w],\n",
    "            randomize = df['randomize'][w],\n",
    "            aota = df['aota'][w], \n",
    "            nota = True\n",
    "        )\n",
    "    elif df['type'][w] == 'True/False':      \n",
    "        q, a = make_true_false(\n",
    "            question = df['question'][w], \n",
    "            answer = df['answer'][w]\n",
    "        )\n",
    "        \n",
    "    print(q)\n",
    "    print(a)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick import from Excel File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
