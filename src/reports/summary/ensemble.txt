Pipeline Description: Final XGBoostGBMModel pipeline with ensemble_level=0 transforming 22 original features -> 22 features in each of 1 models each of 4 fold hyperparameters averaged and re-fit as single model.:
+---------+-----------------+-------------+----------------+-----------+--------------------+-------------+--------------+-------------+--------------------+---------------+---------------+----------------+-----------------+----------------------+-------------------+------------------------------+
|   index | Type            |   Num Folds |   Model Weight | booster   | model_class_name   |   max_depth |   max_leaves |   subsample |   colsample_bytree | tree_method   | grow_policy   |   random_state |   learning rate | Target Transformer   |   Fitted features | Fit iterations [each fold]   |
|---------+-----------------+-------------+----------------+-----------+--------------------+-------------+--------------+-------------+--------------------+---------------+---------------+----------------+-----------------+----------------------+-------------------+------------------------------|
|       0 | XGBoostGBMModel |           4 |              1 | gbtree    | XGBoostGBMModel    |           5 |            0 |         0.6 |                0.5 | gpu_hist      | depthwise     |           1234 |            0.05 | LabelEncoder         |                22 | [116]                        |
+---------+-----------------+-------------+----------------+-----------+--------------------+-------------+--------------+-------------+--------------------+---------------+---------------+----------------+-----------------+----------------------+-------------------+------------------------------+
+---------+-----------+--------------------+----------+----------+----------+---------------+-------------+----------+----------------+----------------+---------------+-----------+-------+------------+----------------+----------+-------+----------------+-----------------+-------------------------+-------------+--------------+---------+-----------+--------------------+------------------+--------------------+-------------+--------------------+---------------+---------------+-------------+--------------+-----------------+---------------+----------------------------+----------+-----------------+--------+----------------+-------------+---------+------------+------------------+--------------------+------------------+---------------+---------------+----------------+------------------------------------------------+
|   index | booster   | model_class_name   |   n_gpus |   gpu_id |   n_jobs |   num_classes |   num_class | labels   | score_f_name   |   random_state | time_column   | encoder   | tgc   | pred_gap   | pred_periods   | target   | tsp   |   n_estimators |   learning_rate | early_stopping_rounds   |   reg_alpha |   reg_lambda |   gamma |   max_bin |   scale_pos_weight |   max_delta_step |   min_child_weight |   subsample |   colsample_bytree | tree_method   | grow_policy   |   max_depth |   max_leaves | objective       | eval_metric   |   early_stopping_threshold | silent   |   debug_verbose |   seed | disable_gpus   | lossguide   | dummy   |   accuracy |   time_tolerance |   interpretability |   ensemble_level | train_shape   | valid_shape   | model_origin   | monotone_constraints                           |
|---------+-----------+--------------------+----------+----------+----------+---------------+-------------+----------+----------------+----------------+---------------+-----------+-------+------------+----------------+----------+-------+----------------+-----------------+-------------------------+-------------+--------------+---------+-----------+--------------------+------------------+--------------------+-------------+--------------------+---------------+---------------+-------------+--------------+-----------------+---------------+----------------------------+----------+-----------------+--------+----------------+-------------+---------+------------+------------------+--------------------+------------------+---------------+---------------+----------------+------------------------------------------------|
|       0 | gbtree    | XGBoostGBMModel    |        1 |        0 |        4 |             2 |           1 | [0, 1]   | AUC            |           1234 |               |           |       |            |                |          |       |            116 |            0.05 |                         |           0 |           10 |    0.01 |       128 |                  1 |                0 |                  1 |         0.6 |                0.5 | gpu_hist      | depthwise     |           5 |            0 | binary:logistic | aucpr         |                          0 | True     |               0 |   1234 | False          | False       | False   |          3 |                3 |                  8 |                1 | (23999, 25)   |               | SEQUENCE       | (0,0,0,0,0,0,1,1,1,1,0,1,0,0,0,0,0,0,0,-1,0,0) |
+---------+-----------+--------------------+----------+----------+----------+---------------+-------------+----------+----------------+----------------+---------------+-----------+-------+------------+----------------+----------+-------+----------------+-----------------+-------------------------+-------------+--------------+---------+-----------+--------------------+------------------+--------------------+-------------+--------------------+---------------+---------------+-------------+--------------+-----------------+---------------+----------------------------+----------+-----------------+--------+----------------+-------------+---------+------------+------------------+--------------------+------------------+---------------+---------------+----------------+------------------------------------------------+
+--------------+------------+---------+--------------+--------------------+
|   Individual | Model      | do_te   | num_as_cat   |   interpretability |
|--------------+------------+---------+--------------+--------------------|
|            0 | XGBOOSTGBM | True    | False        |                  8 |
+--------------+------------+---------+--------------+--------------------+
Validation scores on out-of-fold predictions:
+---------+----------+------------+-----------+----------+----------+----------+----------+----------+------------+----------+
|   index |      MCC |   MACROAUC |   LOGLOSS |     GINI |       F2 |       F1 |      F05 |    AUCPR |   ACCURACY |      AUC |
|---------+----------+------------+-----------+----------+----------+----------+----------+----------+------------+----------|
|       0 | 0.415386 |   0.777616 |  0.433729 | 0.555233 | 0.638654 | 0.543876 | 0.562853 | 0.533133 |   0.813867 | 0.777616 |
+---------+----------+------------+-----------+----------+----------+----------+----------+----------+------------+----------+
ROC metrics on validation (internal or external holdout(s)) data:
+---------+-------------------------+------------------+------------------+-------------------+-------------------+-----------------------+----------------------+------------+-------------+-------------+-------------+-----------+
|   index |   Probability Threshold |   True Positives |   True Negatives |   False Positives |   False Negatives |   False Positive Rate |   True Positive Rate |   Accuracy |   Precision |      Recall |          F1 |       MCC |
|---------+-------------------------+------------------+------------------+-------------------+-------------------+-----------------------+----------------------+------------+-------------+-------------+-------------+-----------|
|       0 |               0         |             5308 |                0 |             18691 |                 0 |            1          |          1           |   0.221176 |    0.221176 | 1           | 0.362234    | 0         |
|       1 |               0.0182091 |             5308 |                0 |             18691 |                 0 |            1          |          1           |   0.221176 |    0.221176 | 1           | 0.362234    | 0         |
|       2 |               0.0410211 |             5301 |              237 |             18454 |                 7 |            0.98732    |          0.998681    |   0.23076  |    0.223153 | 0.998681    | 0.364794    | 0.0470036 |
|       3 |               0.0473252 |             5295 |              475 |             18216 |                13 |            0.974587   |          0.997551    |   0.240427 |    0.225214 | 0.997551    | 0.367466    | 0.0675285 |
|       4 |               0.0524419 |             5285 |              709 |             17982 |                23 |            0.962067   |          0.995667    |   0.24976  |    0.227146 | 0.995667    | 0.369904    | 0.0810943 |
|       5 |               0.0563144 |             5274 |              943 |             17748 |                34 |            0.949548   |          0.993595    |   0.259052 |    0.229085 | 0.993595    | 0.372326    | 0.0925073 |
|       6 |               0.0596648 |             5259 |             1172 |             17519 |                49 |            0.937296   |          0.990769    |   0.267969 |    0.230881 | 0.990769    | 0.374493    | 0.100994  |
|       7 |               0.0625659 |             5246 |             1403 |             17288 |                62 |            0.924937   |          0.98832     |   0.277053 |    0.232804 | 0.98832     | 0.376841    | 0.109878  |
|       8 |               0.0652499 |             5234 |             1635 |             17056 |                74 |            0.912525   |          0.986059    |   0.28622  |    0.234814 | 0.986059    | 0.379303    | 0.118671  |
|       9 |               0.0678189 |             5226 |             1872 |             16819 |                82 |            0.899845   |          0.984552    |   0.295762 |    0.237061 | 0.984552    | 0.382115    | 0.128553  |
|      10 |               0.070066  |             5214 |             2105 |             16586 |                94 |            0.887379   |          0.982291    |   0.304971 |    0.239174 | 0.982291    | 0.384683    | 0.136541  |
|      11 |               0.0723688 |             5200 |             2336 |             16355 |               108 |            0.87502    |          0.979653    |   0.314013 |    0.241243 | 0.979653    | 0.38715     | 0.143591  |
|      12 |               0.0747361 |             5184 |             2564 |             16127 |               124 |            0.862822   |          0.976639    |   0.322847 |    0.243255 | 0.976639    | 0.389496    | 0.149787  |
|      13 |               0.0768352 |             5170 |             2795 |             15896 |               138 |            0.850463   |          0.974002    |   0.331889 |    0.245419 | 0.974002    | 0.392053    | 0.156544  |
|      14 |               0.0789398 |             5148 |             3017 |             15674 |               160 |            0.838585   |          0.969857    |   0.340223 |    0.247238 | 0.969857    | 0.39403     | 0.160761  |
|      15 |               0.0809637 |             5134 |             3248 |             15443 |               174 |            0.826227   |          0.967219    |   0.349265 |    0.249502 | 0.967219    | 0.396678    | 0.167358  |
|      16 |               0.0826303 |             5118 |             3477 |             15214 |               190 |            0.813975   |          0.964205    |   0.35814  |    0.251721 | 0.964205    | 0.39922     | 0.173298  |
|      17 |               0.0843917 |             5108 |             3712 |             14979 |               200 |            0.801402   |          0.962321    |   0.367515 |    0.254294 | 0.962321    | 0.402284    | 0.180814  |
|      18 |               0.0861759 |             5082 |             3930 |             14761 |               226 |            0.789738   |          0.957423    |   0.375516 |    0.25611  | 0.957423    | 0.404119    | 0.183922  |
|      19 |               0.0879158 |             5067 |             4159 |             14532 |               241 |            0.777486   |          0.954597    |   0.384433 |    0.258534 | 0.954597    | 0.406874    | 0.189969  |
|      20 |               0.0899581 |             5049 |             4385 |             14306 |               259 |            0.765395   |          0.951206    |   0.3931   |    0.260863 | 0.951206    | 0.409439    | 0.195213  |
|      21 |               0.0917965 |             5036 |             4616 |             14075 |               272 |            0.753036   |          0.948757    |   0.402183 |    0.263513 | 0.948757    | 0.412466    | 0.201702  |
|      22 |               0.0935052 |             5014 |             4841 |             13850 |               294 |            0.740998   |          0.944612    |   0.410642 |    0.265797 | 0.944612    | 0.41486     | 0.206064  |
|      23 |               0.0956723 |             4993 |             5065 |             13626 |               315 |            0.729014   |          0.940656    |   0.419101 |    0.268167 | 0.940656    | 0.417353    | 0.210627  |
|      24 |               0.0977345 |             4977 |             5293 |             13398 |               331 |            0.716816   |          0.937641    |   0.427934 |    0.270857 | 0.937641    | 0.420301    | 0.216369  |
|      25 |               0.0997657 |             4951 |             5511 |             13180 |               357 |            0.705152   |          0.932743    |   0.435935 |    0.273068 | 0.932743    | 0.422458    | 0.219776  |
|      26 |               0.101957  |             4919 |             5723 |             12968 |               389 |            0.69381    |          0.926714    |   0.443435 |    0.275004 | 0.926714    | 0.424143    | 0.22187   |
|      27 |               0.103882  |             4902 |             5950 |             12741 |               406 |            0.681665   |          0.923512    |   0.452186 |    0.277844 | 0.923512    | 0.427171    | 0.22748   |
|      28 |               0.105762  |             4882 |             6175 |             12516 |               426 |            0.669627   |          0.919744    |   0.460728 |    0.280607 | 0.919744    | 0.430018    | 0.232472  |
|      29 |               0.107996  |             4860 |             6398 |             12293 |               448 |            0.657696   |          0.915599    |   0.469103 |    0.283332 | 0.915599    | 0.43275     | 0.237055  |
|      30 |               0.11013   |             4844 |             6627 |             12064 |               464 |            0.645444   |          0.912585    |   0.477978 |    0.286492 | 0.912585    | 0.436082    | 0.243009  |
|      31 |               0.112192  |             4825 |             6852 |             11839 |               483 |            0.633406   |          0.909005    |   0.486562 |    0.289546 | 0.909005    | 0.439195    | 0.248296  |
|      32 |               0.114417  |             4795 |             7067 |             11624 |               513 |            0.621904   |          0.903353    |   0.494271 |    0.29204  | 0.903353    | 0.441386    | 0.25129   |
|      33 |               0.116378  |             4760 |             7276 |             11415 |               548 |            0.610722   |          0.89676     |   0.501521 |    0.294281 | 0.89676     | 0.443141    | 0.253261  |
|      34 |               0.118382  |             4730 |             7491 |             11200 |               578 |            0.599219   |          0.891108    |   0.50923  |    0.296924 | 0.891108    | 0.445428    | 0.256438  |
|      35 |               0.120265  |             4698 |             7704 |             10987 |               610 |            0.587823   |          0.885079    |   0.516772 |    0.299522 | 0.885079    | 0.447578    | 0.259278  |
|      36 |               0.122143  |             4670 |             7920 |             10771 |               638 |            0.576267   |          0.879804    |   0.524605 |    0.302442 | 0.879804    | 0.450142    | 0.263009  |
|      37 |               0.12413   |             4644 |             8138 |             10553 |               664 |            0.564603   |          0.874906    |   0.532606 |    0.305587 | 0.874906    | 0.452963    | 0.267238  |
|      38 |               0.126217  |             4613 |             8351 |             10340 |               695 |            0.553207   |          0.869066    |   0.540189 |    0.3085   | 0.869066    | 0.455358    | 0.270509  |
|      39 |               0.128342  |             4584 |             8566 |             10125 |               724 |            0.541705   |          0.863602    |   0.547939 |    0.311646 | 0.863602    | 0.458011    | 0.274284  |
|      40 |               0.130495  |             4555 |             8781 |              9910 |               753 |            0.530202   |          0.858139    |   0.55569  |    0.314898 | 0.858139    | 0.460729    | 0.278148  |
|      41 |               0.132727  |             4524 |             8995 |              9696 |               784 |            0.518752   |          0.852298    |   0.563315 |    0.318143 | 0.852298    | 0.463335    | 0.281735  |
|      42 |               0.134554  |             4491 |             9207 |              9484 |               817 |            0.50741    |          0.846081    |   0.570774 |    0.32136  | 0.846081    | 0.465799    | 0.285012  |
|      43 |               0.136865  |             4452 |             9412 |              9279 |               856 |            0.496442   |          0.838734    |   0.577691 |    0.32423  | 0.838734    | 0.467672    | 0.287134  |
|      44 |               0.138918  |             4411 |             9615 |              9076 |               897 |            0.485581   |          0.83101     |   0.584441 |    0.327056 | 0.83101     | 0.46938     | 0.288961  |
|      45 |               0.141063  |             4370 |             9818 |              8873 |               938 |            0.47472    |          0.823286    |   0.591191 |    0.329986 | 0.823286    | 0.471134    | 0.290902  |
|      46 |               0.143397  |             4337 |            10030 |              8661 |               971 |            0.463378   |          0.817069    |   0.59865  |    0.333667 | 0.817069    | 0.473834    | 0.294612  |
|      47 |               0.145556  |             4308 |            10246 |              8445 |              1000 |            0.451822   |          0.811605    |   0.606442 |    0.337803 | 0.811605    | 0.47705     | 0.299239  |
|      48 |               0.14782   |             4265 |            10449 |              8242 |              1043 |            0.440961   |          0.803504    |   0.613109 |    0.341009 | 0.803504    | 0.47881     | 0.301208  |
|      49 |               0.150049  |             4223 |            10651 |              8040 |              1085 |            0.430154   |          0.795592    |   0.619776 |    0.344369 | 0.795592    | 0.480678    | 0.303415  |
|      50 |               0.152401  |             4191 |            10863 |              7828 |              1117 |            0.418811   |          0.789563    |   0.627276 |    0.348698 | 0.789563    | 0.483754    | 0.307753  |
|      51 |               0.154777  |             4146 |            11062 |              7629 |              1162 |            0.408164   |          0.781085    |   0.633693 |    0.352102 | 0.781085    | 0.485395    | 0.309607  |
|      52 |               0.157236  |             4115 |            11275 |              7416 |              1193 |            0.396768   |          0.775245    |   0.641277 |    0.356864 | 0.775245    | 0.488746    | 0.314404  |
|      53 |               0.159719  |             4080 |            11485 |              7206 |              1228 |            0.385533   |          0.768651    |   0.648569 |    0.36151  | 0.768651    | 0.491744    | 0.318581  |
|      54 |               0.162078  |             4039 |            11690 |              7001 |              1269 |            0.374565   |          0.760927    |   0.655402 |    0.365851 | 0.760927    | 0.494128    | 0.32174   |
|      55 |               0.164506  |             4005 |            11902 |              6789 |              1303 |            0.363223   |          0.754521    |   0.662819 |    0.371039 | 0.754521    | 0.497454    | 0.32646   |
|      56 |               0.16755   |             3953 |            12094 |              6597 |              1355 |            0.352951   |          0.744725    |   0.668653 |    0.374692 | 0.744725    | 0.49855     | 0.327602  |
|      57 |               0.170312  |             3912 |            12297 |              6394 |              1396 |            0.34209    |          0.737001    |   0.675403 |    0.379585 | 0.737001    | 0.501089    | 0.331121  |
|      58 |               0.173775  |             3862 |            12491 |              6200 |              1446 |            0.33171    |          0.727581    |   0.681403 |    0.38382  | 0.727581    | 0.502537    | 0.332972  |
|      59 |               0.177297  |             3822 |            12696 |              5995 |              1486 |            0.320743   |          0.720045    |   0.688279 |    0.389325 | 0.720045    | 0.505388    | 0.337074  |
|      60 |               0.180975  |             3779 |            12899 |              5792 |              1529 |            0.309882   |          0.711944    |   0.694946 |    0.394839 | 0.711944    | 0.507964    | 0.340795  |
|      61 |               0.184257  |             3752 |            13116 |              5575 |              1556 |            0.298272   |          0.706858    |   0.702863 |    0.402273 | 0.706858    | 0.512743    | 0.347896  |
|      62 |               0.188009  |             3702 |            13310 |              5381 |              1606 |            0.287893   |          0.697438    |   0.708863 |    0.407575 | 0.697438    | 0.514488    | 0.350463  |
|      63 |               0.192595  |             3666 |            13518 |              5173 |              1642 |            0.276764   |          0.690656    |   0.71603  |    0.414753 | 0.690656    | 0.518272    | 0.356137  |
|      64 |               0.197688  |             3619 |            13715 |              4976 |              1689 |            0.266224   |          0.681801    |   0.72228  |    0.421059 | 0.681801    | 0.520607    | 0.359744  |
|      65 |               0.202515  |             3578 |            13919 |              4772 |              1730 |            0.25531    |          0.674077    |   0.729072 |    0.428503 | 0.674077    | 0.523942    | 0.364895  |
|      66 |               0.207832  |             3522 |            14110 |              4581 |              1786 |            0.245091   |          0.663527    |   0.734697 |    0.434654 | 0.663527    | 0.52524     | 0.367234  |
|      67 |               0.213093  |             3481 |            14313 |              4378 |              1827 |            0.23423    |          0.655803    |   0.741448 |    0.442932 | 0.655803    | 0.528746    | 0.372836  |
|      68 |               0.218912  |             3422 |            14498 |              4193 |              1886 |            0.224333   |          0.644687    |   0.746698 |    0.449376 | 0.644687    | 0.529598    | 0.374846  |
|      69 |               0.224861  |             3375 |            14695 |              3996 |              1933 |            0.213793   |          0.635833    |   0.752948 |    0.457875 | 0.635833    | 0.532376    | 0.37971   |
|      70 |               0.231783  |             3324 |            14888 |              3803 |              1984 |            0.203467   |          0.626225    |   0.758865 |    0.466395 | 0.626225    | 0.53462     | 0.384005  |
|      71 |               0.238614  |             3268 |            15078 |              3613 |              2040 |            0.193302   |          0.615674    |   0.764449 |    0.474931 | 0.615674    | 0.536221    | 0.387637  |
|      72 |               0.245771  |             3215 |            15274 |              3417 |              2093 |            0.182815   |          0.60569     |   0.770407 |    0.484771 | 0.60569     | 0.538526    | 0.392472  |
|      73 |               0.253909  |             3159 |            15464 |              3227 |              2149 |            0.17265    |          0.595139    |   0.775991 |    0.494676 | 0.595139    | 0.540277    | 0.396795  |
|      74 |               0.262687  |             3106 |            15656 |              3035 |              2202 |            0.162378   |          0.585154    |   0.781783 |    0.505781 | 0.585154    | 0.54258     | 0.402121  |
|      75 |               0.271987  |             3035 |            15830 |              2861 |              2273 |            0.153068   |          0.571778    |   0.786074 |    0.514756 | 0.571778    | 0.541771    | 0.403684  |
|      76 |               0.283592  |             2978 |            16018 |              2673 |              2330 |            0.14301    |          0.56104     |   0.791533 |    0.526986 | 0.56104     | 0.54348     | 0.408914  |
|      77 |               0.284411  |             2975 |            16034 |              2657 |              2333 |            0.142154   |          0.560475    |   0.792075 |    0.528232 | 0.560475    | 0.543876    | 0.409676  |
|      78 |               0.296549  |             2908 |            16192 |              2499 |              2400 |            0.133701   |          0.547852    |   0.795866 |    0.537821 | 0.547852    | 0.54279     | 0.411434  |
|      79 |               0.310911  |             2836 |            16368 |              2323 |              2472 |            0.124284   |          0.534288    |   0.8002   |    0.549719 | 0.534288    | 0.541894    | 0.414234  |
|      80 |               0.326309  |             2749 |            16537 |              2154 |              2559 |            0.115243   |          0.517898    |   0.803617 |    0.560677 | 0.517898    | 0.538439    | 0.414489  |
|      81 |               0.329688  |             2731 |            16581 |              2110 |              2577 |            0.112889   |          0.514506    |   0.8047   |    0.56414  | 0.514506    | 0.538181    | 0.415386  |
|      82 |               0.344367  |             2661 |            16696 |              1995 |              2647 |            0.106736   |          0.501319    |   0.806575 |    0.571521 | 0.501319    | 0.534123    | 0.414144  |
|      83 |               0.365824  |             2554 |            16840 |              1851 |              2754 |            0.0990316  |          0.481161    |   0.808117 |    0.579796 | 0.481161    | 0.525893    | 0.409692  |
|      84 |               0.390693  |             2455 |            16987 |              1704 |              2853 |            0.0911669  |          0.462509    |   0.810117 |    0.590286 | 0.462509    | 0.518644    | 0.407184  |
|      85 |               0.41574   |             2352 |            17131 |              1560 |              2956 |            0.0834626  |          0.443105    |   0.811825 |    0.601227 | 0.443105    | 0.510195    | 0.404106  |
|      86 |               0.43647   |             2243 |            17269 |              1422 |              3065 |            0.0760794  |          0.42257     |   0.813034 |    0.612005 | 0.42257     | 0.499944    | 0.399783  |
|      87 |               0.458603  |             2122 |            17393 |              1298 |              3186 |            0.0694452  |          0.399774    |   0.813159 |    0.620468 | 0.399774    | 0.486251    | 0.392196  |
|      88 |               0.476312  |             2034 |            17498 |              1193 |              3274 |            0.0638275  |          0.383195    |   0.813867 |    0.630307 | 0.383195    | 0.476626    | 0.388538  |
|      89 |               0.481155  |             2008 |            17523 |              1168 |              3300 |            0.06249    |          0.378297    |   0.813826 |    0.632242 | 0.378297    | 0.473362    | 0.386804  |
|      90 |               0.50438   |             1879 |            17638 |              1053 |              3429 |            0.0563373  |          0.353994    |   0.813242 |    0.640859 | 0.353994    | 0.456068    | 0.377237  |
|      91 |               0.526112  |             1740 |            17743 |               948 |              3568 |            0.0507196  |          0.327807    |   0.811825 |    0.647321 | 0.327807    | 0.435218    | 0.364655  |
|      92 |               0.546372  |             1609 |            17856 |               835 |              3699 |            0.0446739  |          0.303127    |   0.811075 |    0.658347 | 0.303127    | 0.415119    | 0.354682  |
|      93 |               0.563246  |             1460 |            17952 |               739 |              3848 |            0.0395377  |          0.275057    |   0.808867 |    0.663938 | 0.275057    | 0.38897     | 0.338818  |
|      94 |               0.58175   |             1318 |            18054 |               637 |              3990 |            0.0340806  |          0.248304    |   0.8072   |    0.674169 | 0.248304    | 0.362935    | 0.325036  |
|      95 |               0.59946   |             1166 |            18146 |               545 |              4142 |            0.0291584  |          0.219668    |   0.8047   |    0.681473 | 0.219668    | 0.332241    | 0.307283  |
|      96 |               0.620034  |             1017 |            18241 |               450 |              4291 |            0.0240758  |          0.191598    |   0.80245  |    0.693252 | 0.191598    | 0.300221    | 0.290227  |
|      97 |               0.63842   |              860 |            18328 |               363 |              4448 |            0.0194211  |          0.16202     |   0.799533 |    0.703189 | 0.16202     | 0.263359    | 0.269119  |
|      98 |               0.660468  |              694 |            18406 |               285 |              4614 |            0.015248   |          0.130746    |   0.795866 |    0.708887 | 0.130746    | 0.220773    | 0.242333  |
|      99 |               0.681556  |              530 |            18487 |               204 |              4778 |            0.0109143  |          0.0998493   |   0.792408 |    0.722071 | 0.0998493   | 0.175439    | 0.214365  |
|     100 |               0.708996  |              359 |            18560 |               131 |              4949 |            0.00700872 |          0.0676338   |   0.788325 |    0.732653 | 0.0676338   | 0.123836    | 0.177917  |
|     101 |               0.743207  |              192 |            18638 |                53 |              5116 |            0.00283559 |          0.0361718   |   0.784616 |    0.783673 | 0.0361718   | 0.0691518   | 0.137641  |
|     102 |               0.856642  |                7 |            18691 |                 0 |              5301 |            0          |          0.00131876  |   0.779116 |    1        | 0.00131876  | 0.00263405  | 0.0320528 |
|     103 |               0.876966  |                1 |            18691 |                 0 |              5307 |            0          |          0.000188395 |   0.778866 |    1        | 0.000188395 | 0.000376719 | 0.0121133 |
|     104 |               1         |                1 |            18691 |                 0 |              5307 |            0          |          0.000188395 |   0.778866 |    1        | 0.000188395 | 0.000376719 | 0.0121133 |
+---------+-------------------------+------------------+------------------+-------------------+-------------------+-----------------------+----------------------+------------+-------------+-------------+-------------+-----------+
Gains/Lift table on validation (internal or external holdout(s)) data:
+---------+------------+-----------+---------+-----------+
|   index |   quantile |      gain |    lift |       k-s |
|---------+------------+-----------+---------+-----------|
|       0 |       0.01 | 0.0356066 | 3.56066 | 0.0329315 |
|       1 |       0.02 | 0.066315  | 3.31575 | 0.0595203 |
|       2 |       0.03 | 0.0977769 | 3.25923 | 0.0870766 |
|       3 |       0.04 | 0.128485  | 3.21213 | 0.113665  |
|       4 |       0.05 | 0.15844   | 3.1688  | 0.139286  |
|       5 |       0.1  | 0.298229  | 2.98229 | 0.254572  |
|       6 |       0.15 | 0.416918  | 2.77945 | 0.342765  |
|       7 |       0.2  | 0.510173  | 2.55087 | 0.398301  |
|       8 |       0.3  | 0.629239  | 2.09746 | 0.422776  |
|       9 |       0.4  | 0.712133  | 1.78033 | 0.400806  |
|      10 |       0.5  | 0.788998  | 1.578   | 0.371096  |
|      11 |       0.6  | 0.856443  | 1.42741 | 0.329291  |
|      12 |       0.7  | 0.910701  | 1.301   | 0.270553  |
|      13 |       0.8  | 0.950452  | 1.18807 | 0.193189  |
|      14 |       0.9  | 0.979842  | 1.08871 | 0.102521  |
|      15 |       1    | 1         | 1       | 0         |
+---------+------------+-----------+---------+-----------+
Confusion matrix on validation (internal or external holdout(s)) data:
+----+-------+------+
|    |     0 |    1 |
|----+-------+------|
|  0 | 16034 | 2657 |
|  1 |  2333 | 2975 |
+----+-------+------+

Detailed confusion matrix statistics on validation (internal or external holdout(s)) data:
+---------------------------------------+--------------+--------------+
|                                       |            0 |            1 |
|---------------------------------------+--------------+--------------|
| Threshold (max F1 score)              |     0.284411 |     0.284411 |
| Population                            | 23999        | 23999        |
| P: Condition positive                 | 18691        |  5308        |
| N: Condition negative                 |  5308        | 18691        |
| Test outcome positive                 | 18367        |  5632        |
| Test outcome negative                 |  5632        | 18367        |
| TP: True Positive                     | 16034        |  2975        |
| TN: True Negative                     |  2975        | 16034        |
| FP: False Positive                    |  2333        |  2657        |
| FN: False Negative                    |  2657        |  2333        |
| TPR: (Sensitivity, hit rate, recall)  |     0.857846 |     0.560475 |
| TNR=SPC: (Specificity)                |     0.560475 |     0.857846 |
| PPV: Pos Pred Value (Precision)       |     0.872979 |     0.528232 |
| NPV: Neg Pred Value                   |     0.528232 |     0.872979 |
| FPR: False-out                        |     0.439525 |     0.142154 |
| FDR: False Discovery Rate             |     0.127021 |     0.471768 |
| FNR: Miss Rate                        |     0.142154 |     0.439525 |
| ACC: Accuracy                         |     0.792075 |     0.792075 |
| F1 score                              |     0.865346 |     0.543876 |
| MCC: Matthews correlation coefficient |     0.409676 |     0.409676 |
| Informedness                          |     0.418321 |     0.418321 |
| Markedness                            |     0.40121  |     0.40121  |
| Prevalence                            |     0.778824 |     0.221176 |
| LR+: Positive likelihood ratio        |     1.95176  |     3.94273  |
| LR-: Negative likelihood ratio        |     0.253631 |     0.512359 |
| DOR: Diagnostic odds ratio            |     7.69525  |     7.69525  |
| FOR: False omission rate              |     0.471768 |     0.127021 |
+---------------------------------------+--------------+--------------+
+----------+-----------------------------------------------------------------------------------------------------+-------------+-------------------+
| Scorer   | Final ensemble scores +/- standard deviation on validation (internal or external holdout(s)) data   | Optimized   | Better score is   |
|----------+-----------------------------------------------------------------------------------------------------+-------------+-------------------|
| MCC      | 0.4153862 +/- 0.008276535                                                                           |             | higher            |
| MACROAUC | 0.7776164 +/- 0.003504786                                                                           |             | higher            |
| LOGLOSS  | 0.4337286 +/- 0.003290567                                                                           |             | lower             |
| GINI     | 0.5552328 +/- 0.007009572                                                                           |             | higher            |
| F2       | 0.6386541 +/- 0.004620936                                                                           |             | higher            |
| F1       | 0.5438757 +/- 0.006514066                                                                           |             | higher            |
| F05      | 0.5628527 +/- 0.007161527                                                                           |             | higher            |
| AUCPR    | 0.533133 +/- 0.008701996                                                                            |             | higher            |
| ACCURACY | 0.8138672 +/- 0.002481037                                                                           |             | higher            |
| AUC      | 0.7776164 +/- 0.003504786                                                                           | *           | higher            |
+----------+-----------------------------------------------------------------------------------------------------+-------------+-------------------+
